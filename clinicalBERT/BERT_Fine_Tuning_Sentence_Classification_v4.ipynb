{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKOTlwcmxmej"
   },
   "source": [
    "# BERT Fine-Tuning Tutorial with PyTorch\n",
    "\n",
    "By Chris McCormick and Nick Ryan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPgpITmdwvX0"
   },
   "source": [
    "*Revised on March 20, 2020 - Switched to `tokenizer.encode_plus` and added validation loss. See [Revision History](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=IKzLS9ohzGVu) at the end for details.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJR6t_gCQe_x"
   },
   "source": [
    "In this tutorial I'll show you how to use BERT with the huggingface PyTorch library to quickly and efficiently fine-tune a model to get near state of the art performance in sentence classification. More broadly, I describe the practical application of transfer learning in NLP to create high performance models with minimal effort on a range of NLP tasks.\n",
    "\n",
    "This post is presented in two forms--as a blog post [here](http://mccormickml.com/2019/07/22/BERT-fine-tuning/) and as a Colab Notebook [here](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX). \n",
    "\n",
    "The content is identical in both, but: \n",
    "* The blog post includes a comments section for discussion. \n",
    "* The Colab Notebook will allow you to run the code and inspect it as you read through.\n",
    "\n",
    "I've also published a video walkthrough of this post on my YouTube channel! [Part 1](https://youtu.be/x66kkDnbzi4) and [Part 2](https://youtu.be/Hnvb9b7a_Ps).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrC9__lXxTJz"
   },
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9MCBOq4xUpr"
   },
   "source": [
    "See \"Table of contents\" in the sidebar to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADkUGTqixRWo"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9vxxTBsuL24"
   },
   "source": [
    "\n",
    "## History\n",
    "\n",
    "2018 was a breakthrough year in NLP. Transfer learning, particularly models like Allen AI's ELMO, OpenAI's Open-GPT, and Google's BERT allowed researchers to smash multiple benchmarks with minimal task-specific fine-tuning and provided the rest of the NLP community with pretrained models that could easily (with less data and less compute time) be fine-tuned and implemented to produce state of the art results. Unfortunately, for many starting out in NLP and even for some experienced practicioners, the theory and practical application of these powerful models is still not well understood.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCgvR9INuP5q"
   },
   "source": [
    "\n",
    "## What is BERT?\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers), released in late 2018, is the model we will use in this tutorial to provide readers with a better understanding of and practical guidance for using transfer learning models in NLP. BERT is a method of pretraining language representations that was used to create models that NLP practicioners can then download and use for free. You can either use these models to extract high quality language features from your text data, or you can fine-tune these models on a specific task (classification, entity recognition, question answering, etc.) with your own data to produce state of the art predictions.\n",
    "\n",
    "This post will explain how you can modify and fine-tune BERT to create a powerful NLP model that quickly gives you state of the art results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaVGdtOkuXUZ"
   },
   "source": [
    "\n",
    "## Advantages of Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5llwu8GBuqMb"
   },
   "source": [
    "\n",
    "In this tutorial, we will use BERT to train a text classifier. Specifically, we will take the pre-trained BERT model, add an untrained layer of neurons on the end, and train the new model for our classification task. Why do this rather than train a train a specific deep learning model (a CNN, BiLSTM, etc.) that is well suited for the specific NLP task you need? \n",
    "\n",
    "1. **Quicker Development**\n",
    "\n",
    "    * First, the pre-trained BERT model weights already encode a lot of information about our language. As a result, it takes much less time to train our fine-tuned model - it is as if we have already trained the bottom layers of our network extensively and only need to gently tune them while using their output as features for our classification task. In fact, the authors recommend only 2-4 epochs of training for fine-tuning BERT on a specific NLP task (compared to the hundreds of GPU hours needed to train the original BERT model or a LSTM from scratch!). \n",
    "\n",
    "2. **Less Data**\n",
    "\n",
    "    * In addition and perhaps just as important, because of the pre-trained weights this method allows us to fine-tune our task on a much smaller dataset than would be required in a model that is built from scratch. A major drawback of NLP models built from scratch is that we often need a prohibitively large dataset in order to train our network to reasonable accuracy, meaning a lot of time and energy had to be put into dataset creation. By fine-tuning BERT, we are now able to get away with training a model to good performance on a much smaller amount of training data.\n",
    "\n",
    "3. **Better Results**\n",
    "\n",
    "    * Finally, this simple fine-tuning procedure (typically adding one fully-connected layer on top of BERT and training for a few epochs) was shown to achieve state of the art results with minimal task-specific adjustments for a wide variety of tasks: classification, language inference, semantic similarity, question answering, etc. Rather than implementing custom and sometimes-obscure architetures shown to work well on a specific task, simply fine-tuning BERT is shown to be a better (or at least equal) alternative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEynC5F4u7Nb"
   },
   "source": [
    "\n",
    "### A Shift in NLP\n",
    "\n",
    "This shift to transfer learning parallels the same shift that took place in computer vision a few years ago. Creating a good deep learning network for computer vision tasks can take millions of parameters and be very expensive to train. Researchers discovered that deep networks learn hierarchical feature representations (simple features like edges at the lowest layers with gradually more complex features at higher layers). Rather than training a new network from scratch each time, the lower layers of a trained network with generalized image features could be copied and transfered for use in another network with a different task. It soon became common practice to download a pre-trained deep network and quickly retrain it for the new task or add additional layers on top - vastly preferable to the expensive process of training a network from scratch. For many, the introduction of deep pre-trained language models in 2018 (ELMO, BERT, ULMFIT, Open-GPT, etc.) signals the same shift to transfer learning in NLP that computer vision saw.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-Th8bRio6A4"
   },
   "source": [
    "\n",
    "[![BERT eBook Display Ad](https://drive.google.com/uc?export=view&id=1d6L584QYqpREpRIwAZ55Wsq8AUs5qSk1)](https://bit.ly/30JzuBH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX_ZDhicpHkV"
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSU7yERLP_66"
   },
   "source": [
    "## 1.1. Using Colab GPU for Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI0iOY8zvZzL"
   },
   "source": [
    "\n",
    "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
    "\n",
    "A GPU can be added by going to the menu and selecting:\n",
    "\n",
    "`Edit 🡒 Notebook Settings 🡒 Hardware accelerator 🡒 (GPU)`\n",
    "\n",
    "Then run the following cell to confirm that the GPU is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEfSbAA4QHas",
    "outputId": "4ef6084c-1b3b-4f8e-b8dd-92422875a242"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Get the GPU device name.\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# # The device name should look like the following:\n",
    "# if device_name == '/device:GPU:0':\n",
    "#     print('Found GPU at: {}'.format(device_name))\n",
    "# else:\n",
    "#     raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqG7FzRVFEIv"
   },
   "source": [
    "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "2e60467d-6a6b-4898-e2f4-f42884cc6092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1050 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ElsnSNUridI"
   },
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_N2UDLevYWn"
   },
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NmMdkZO8R6q",
    "outputId": "5a35e119-1349-4c99-8ec5-37da3fe09833"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxddqmruamSj"
   },
   "source": [
    "The code in this notebook is actually a simplified version of the [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) example script from huggingface.\n",
    "\n",
    "`run_glue.py` is a helpful utility which allows you to pick which GLUE benchmark task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up.\n",
    "\n",
    "Unfortunately, all of this configurability comes at the cost of *readability*. In this Notebook, we've simplified the code greatly and added plenty of comments to make it clear what's going on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "# 2. Loading Train and Val datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9ZKxKc04Btk"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQUy9Tat2EF_"
   },
   "source": [
    "## 2.2. Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeyVCXT31EZQ"
   },
   "source": [
    "We can see from the file names that both `tokenized` and `raw` versions of the data are available. \n",
    "\n",
    "We can't use the pre-tokenized version because, in order to apply the pre-trained BERT, we *must* use the tokenizer provided by the model. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYWzeGSY2xh3"
   },
   "source": [
    "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "_UkeC7SG2krJ",
    "outputId": "570f1a76-f163-41e1-b8f5-073bd969f737"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # # Load the dataset into a pandas dataframe.\n",
    "# # df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# df = pd.read_csv(\"./data/3days/train.csv\")\n",
    "\n",
    "# val_df = pd.read_csv(\"./data/3days/val.csv\")\n",
    "# # Report the number of sentences.\n",
    "# print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "# print(f'Number of validation sentenced: {val_df.shape[0]}')\n",
    "\n",
    "# # Display 10 random rows from the data.\n",
    "# df.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "ID            float64\n",
       "TEXT           object\n",
       "Label         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfWzpPi92UAH"
   },
   "source": [
    "The two properties we actually care about are the the `sentence` and its `label`, which is referred to as the \"acceptibility judgment\" (0=unacceptable, 1=acceptable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_LpQfzCn9_o"
   },
   "source": [
    "Here are five sentences which are labeled as not grammatically acceptible. Note how much more difficult this task is than something like sentiment analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "blqIvQaQncdJ",
    "outputId": "ea5e6a0b-23b0-42d6-9b05-0e136f6ee5b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30661</th>\n",
       "      <td>sinus arrhythmia left axis deviation - anterio...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46267</th>\n",
       "      <td>1-9 1615 hct recieving lr @ 75 ml/hr presently...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25525</th>\n",
       "      <td>sinus rhythm. normal tracing. no previous trac...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21188</th>\n",
       "      <td>1,000 ml 600 ml blood products: total out: 0 m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37456</th>\n",
       "      <td>tsicu npn 7p-7a s/o- pt sedated over night on ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    TEXT  Label\n",
       "30661  sinus arrhythmia left axis deviation - anterio...    0.0\n",
       "46267  1-9 1615 hct recieving lr @ 75 ml/hr presently...    0.0\n",
       "25525  sinus rhythm. normal tracing. no previous trac...    0.0\n",
       "21188  1,000 ml 600 ml blood products: total out: 0 m...    0.0\n",
       "37456  tsicu npn 7p-7a s/o- pt sedated over night on ...    0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[df.Label == 0].sample(5)[['TEXT', 'Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SMZ5T5Imhlx"
   },
   "source": [
    "\n",
    "\n",
    "Let's extract the sentences and labels of our training set as numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GuE5BqICAne2"
   },
   "outputs": [],
   "source": [
    "# # Get the lists of sentences and their labels.\n",
    "# sentences = df.TEXT.values\n",
    "# labels = df.Label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "# 3. Tokenization & Input Formatting\n",
    "\n",
    "In this section, we'll transform our dataset into the format that BERT can be trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8kEDRvShcU5"
   },
   "source": [
    "## 3.1. BERT Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWOPOyWghJp2"
   },
   "source": [
    "\n",
    "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
    "\n",
    "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "82ddfcea0e4c4e5a86cf6eca8585be8d",
      "8a256ba4a19e4ec98fe3c3c99fba4daa",
      "8c76faadf2f4415393c6f0a805f0d72b",
      "e0bb735fda99434a90380e7fc664212d",
      "cdb78e75309f4bc09366533331e72431",
      "1058e0b5baa248faa60c1ad146d10bf7",
      "375cc635389c4ddb9bf2aa443df58bae",
      "472198d5b6a748b3a81f9364fd1fa711"
     ]
    },
    "id": "Z474sSC6oe7A",
    "outputId": "4e6d97b6-2d4c-42ca-c201-d2b4a88895b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(\"./model/pretraining/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFzmtleW6KmJ"
   },
   "source": [
    "Let's apply the tokenizer to one sentence just to see the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLIbudgfh6F0",
    "outputId": "9ca681ff-195f-4960-a0ba-55ded440278e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  have a significant family history of cancer. occupation: drugs: tobacco: alcohol: other: (per omr): the patient is a previous mechanical engineer. he smoked occasionally but quit 35 years ago. he denies any alcohol use. lives alone and is independent. no close relatives in the area. siblings in . review of systems: flowsheet data as of 10:26 pm vital signs hemodynamic monitoring fluid balance 24 hours since am tmax: 6 c (8 tcurrent: 6 c (8 hr: 106 (106 - 121) bpm bp: 129/59(72) {129/58(72) - 130/59(78)} mmhg rr: 19 (19 - 28) insp/min spo2: 95% heart rhythm: st (sinus tachycardia) total in: 382 ml po: tf: ivf: 7 ml blood products: 375 ml total out: 0 ml 210 ml urine: 210 ml ng: stool: drains: balance: 0 ml 172 ml respiratory o2 delivery device: nasal cannula spo2: 95% physical examination vitals: t: 8 bp:130/70 p:113 r: 18 o2: 97on 4l nc general: alert, oriented, no acute distress heent: sclera anicteric, mmm, oropharynx clear neck: supple, jvp 3cm above clavicle, no lad lungs: wheezes anteriorly with rales at bilateral bases cv: tachycardic, irregularly irregular, no murmurs, rubs, gallops abdomen: soft, non-tender, non-distended, bowel sounds present, no rebound tenderness or guarding, no organomegaly gu: no foley ext: warm, well perfused, edema bilaterally to shins. left foot erythematous, warm, slight ttp labs / radiology fluid analysis / other labs: notable for: hct 6 bnp 6751 ck 39 trop 04 mb not done bun/creatinine 39/1 lactate 0 imaging: ct abd/pelvis (wet read - ? error given comment on only lungs . . .) no small bowel obstruction. tree-in- opacities in right middle and bilateral lower lobes, infectious/inflammatory in nature, could represent aspiration. bibasilar atelectasis, but out of proportion to small bilateral pleural effusions, may represent infectious consolidations also. anemia. . echo (): the left atrium is normal in size. the estimated right atrial pressure is 0-5 mmhg. left ventricular wall thicknesses and\n",
      "Tokenized:  ['have', 'a', 'significant', 'family', 'history', 'of', 'cancer', '.', 'occupation', ':', 'drugs', ':', 'tobacco', ':', 'alcohol', ':', 'other', ':', '(', 'per', 'o', '##m', '##r', ')', ':', 'the', 'patient', 'is', 'a', 'previous', 'mechanical', 'engineer', '.', 'he', 'smoked', 'occasionally', 'but', 'quit', '35', 'years', 'ago', '.', 'he', 'denies', 'any', 'alcohol', 'use', '.', 'lives', 'alone', 'and', 'is', 'independent', '.', 'no', 'close', 'relatives', 'in', 'the', 'area', '.', 'siblings', 'in', '.', 'review', 'of', 'systems', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '10', ':', '26', 'pm', 'vital', 'signs', 'hem', '##ody', '##nam', '##ic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'am', 't', '##max', ':', '6', 'c', '(', '8', 't', '##current', ':', '6', 'c', '(', '8', 'h', '##r', ':', '106', '(', '106', '-', '121', ')', 'b', '##pm', 'b', '##p', ':', '129', '/', '59', '(', '72', ')', '{', '129', '/', '58', '(', '72', ')', '-', '130', '/', '59', '(', '78', ')', '}', 'mm', '##h', '##g', 'r', '##r', ':', '19', '(', '19', '-', '28', ')', 'ins', '##p', '/', 'min', 's', '##po', '##2', ':', '95', '%', 'heart', 'rhythm', ':', 's', '##t', '(', 'sin', '##us', 'ta', '##chy', '##card', '##ia', ')', 'total', 'in', ':', '38', '##2', 'm', '##l', 'p', '##o', ':', 't', '##f', ':', 'i', '##v', '##f', ':', '7', 'm', '##l', 'blood', 'products', ':', '375', 'm', '##l', 'total', 'out', ':', '0', 'm', '##l', '210', 'm', '##l', 'urine', ':', '210', 'm', '##l', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '0', 'm', '##l', '172', 'm', '##l', 'respiratory', 'o', '##2', 'delivery', 'device', ':', 'nasal', 'can', '##nu', '##la', 's', '##po', '##2', ':', '95', '%', 'physical', 'examination', 'vital', '##s', ':', 't', ':', '8', 'b', '##p', ':', '130', '/', '70', 'p', ':', '113', 'r', ':', '18', 'o', '##2', ':', '97', '##on', '4', '##l', 'n', '##c', 'general', ':', 'alert', ',', 'oriented', ',', 'no', 'acute', 'distress', 'he', '##ent', ':', 's', '##cle', '##ra', 'an', '##ict', '##eric', ',', 'mm', '##m', ',', 'or', '##op', '##har', '##ynx', 'clear', 'neck', ':', 'su', '##pp', '##le', ',', 'j', '##v', '##p', '3', '##c', '##m', 'above', 'c', '##lav', '##icle', ',', 'no', 'lad', 'lungs', ':', 'w', '##hee', '##zes', 'anterior', '##ly', 'with', 'r', '##ales', 'at', 'bilateral', 'bases', 'c', '##v', ':', 'ta', '##chy', '##card', '##ic', ',', 'irregular', '##ly', 'irregular', ',', 'no', 'murmurs', ',', 'rub', '##s', ',', 'gal', '##lops', 'abdomen', ':', 'soft', ',', 'non', '-', 'tender', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'bow', '##el', 'sounds', 'present', ',', 'no', 're', '##bound', 'tender', '##ness', 'or', 'guarding', ',', 'no', 'organ', '##ome', '##gal', '##y', 'g', '##u', ':', 'no', 'f', '##ole', '##y', 'ex', '##t', ':', 'warm', ',', 'well', 'per', '##fused', ',', 'ed', '##ema', 'bilateral', '##ly', 'to', 's', '##hin', '##s', '.', 'left', 'foot', 'er', '##yt', '##hem', '##ato', '##us', ',', 'warm', ',', 'slight', 't', '##t', '##p', 'labs', '/', 'radio', '##logy', 'fluid', 'analysis', '/', 'other', 'labs', ':', 'notable', 'for', ':', 'h', '##ct', '6', 'b', '##n', '##p', '67', '##51', 'c', '##k', '39', 't', '##rop', '04', 'm', '##b', 'not', 'done', 'b', '##un', '/', 'c', '##rea', '##tin', '##ine', '39', '/', '1', 'la', '##ct', '##ate', '0', 'imaging', ':', 'c', '##t', 'a', '##b', '##d', '/', 'p', '##el', '##vis', '(', 'wet', 'read', '-', '?', 'error', 'given', 'comment', 'on', 'only', 'lungs', '.', '.', '.', ')', 'no', 'small', 'bow', '##el', 'o', '##bs', '##truction', '.', 'tree', '-', 'in', '-', 'op', '##ac', '##ities', 'in', 'right', 'middle', 'and', 'bilateral', 'lower', 'lobes', ',', 'infectious', '/', 'inflammatory', 'in', 'nature', ',', 'could', 'represent', 'as', '##piration', '.', 'bi', '##bas', '##ila', '##r', 'ate', '##lect', '##asis', ',', 'but', 'out', 'of', 'proportion', 'to', 'small', 'bilateral', 'p', '##le', '##ural', 'e', '##ff', '##usions', ',', 'may', 'represent', 'infectious', 'consolidation', '##s', 'also', '.', 'an', '##emia', '.', '.', 'echo', '(', ')', ':', 'the', 'left', 'at', '##rium', 'is', 'normal', 'in', 'size', '.', 'the', 'estimated', 'right', 'at', '##rial', 'pressure', 'is', '0', '-', '5', 'mm', '##h', '##g', '.', 'left', 'vent', '##ric', '##ular', 'wall', 'thickness', '##es', 'and']\n",
      "Token IDs:  [1138, 170, 2418, 1266, 1607, 1104, 4182, 119, 5846, 131, 5557, 131, 10468, 131, 6272, 131, 1168, 131, 113, 1679, 184, 1306, 1197, 114, 131, 1103, 5351, 1110, 170, 2166, 6676, 3806, 119, 1119, 23235, 5411, 1133, 8204, 2588, 1201, 2403, 119, 1119, 26360, 1251, 6272, 1329, 119, 2491, 2041, 1105, 1110, 2457, 119, 1185, 1601, 8908, 1107, 1103, 1298, 119, 9302, 1107, 119, 3189, 1104, 2344, 131, 5611, 19989, 1204, 2233, 1112, 1104, 1275, 131, 1744, 9852, 9301, 5300, 23123, 22320, 12881, 1596, 9437, 8240, 5233, 1572, 2005, 1290, 1821, 189, 22871, 131, 127, 172, 113, 129, 189, 21754, 131, 127, 172, 113, 129, 177, 1197, 131, 9920, 113, 9920, 118, 12794, 114, 171, 9952, 171, 1643, 131, 14949, 120, 4589, 113, 5117, 114, 196, 14949, 120, 4650, 113, 5117, 114, 118, 7029, 120, 4589, 113, 5603, 114, 198, 2608, 1324, 1403, 187, 1197, 131, 1627, 113, 1627, 118, 1743, 114, 22233, 1643, 120, 11241, 188, 5674, 1477, 131, 4573, 110, 1762, 6795, 131, 188, 1204, 113, 11850, 1361, 27629, 8992, 10542, 1465, 114, 1703, 1107, 131, 3383, 1477, 182, 1233, 185, 1186, 131, 189, 2087, 131, 178, 1964, 2087, 131, 128, 182, 1233, 1892, 2982, 131, 19397, 182, 1233, 1703, 1149, 131, 121, 182, 1233, 13075, 182, 1233, 19968, 131, 13075, 182, 1233, 21174, 131, 15631, 131, 20681, 131, 5233, 131, 121, 182, 1233, 19639, 182, 1233, 19192, 184, 1477, 6779, 4442, 131, 21447, 1169, 14787, 1742, 188, 5674, 1477, 131, 4573, 110, 2952, 8179, 9301, 1116, 131, 189, 131, 129, 171, 1643, 131, 7029, 120, 3102, 185, 131, 12206, 187, 131, 1407, 184, 1477, 131, 5311, 1320, 125, 1233, 183, 1665, 1704, 131, 10427, 117, 7779, 117, 1185, 12104, 13632, 1119, 3452, 131, 188, 10536, 1611, 1126, 17882, 26237, 117, 2608, 1306, 117, 1137, 4184, 7111, 22093, 2330, 2455, 131, 28117, 8661, 1513, 117, 179, 1964, 1643, 124, 1665, 1306, 1807, 172, 9516, 26726, 117, 1185, 19122, 8682, 131, 192, 19989, 11846, 16557, 1193, 1114, 187, 19856, 1120, 20557, 7616, 172, 1964, 131, 27629, 8992, 10542, 1596, 117, 12692, 1193, 12692, 117, 1185, 26792, 117, 16259, 1116, 117, 20003, 22101, 14701, 131, 2991, 117, 1664, 118, 8886, 117, 1664, 118, 4267, 15874, 4902, 117, 7125, 1883, 3807, 1675, 117, 1185, 1231, 8346, 8886, 1757, 1137, 18648, 117, 1185, 5677, 6758, 6997, 1183, 176, 1358, 131, 1185, 175, 9016, 1183, 4252, 1204, 131, 3258, 117, 1218, 1679, 21089, 117, 5048, 14494, 20557, 1193, 1106, 188, 8265, 1116, 119, 1286, 2555, 14044, 25669, 15391, 10024, 1361, 117, 3258, 117, 6812, 189, 1204, 1643, 21973, 120, 2070, 6360, 8240, 3622, 120, 1168, 21973, 131, 3385, 1111, 131, 177, 5822, 127, 171, 1179, 1643, 5486, 24050, 172, 1377, 3614, 189, 12736, 5129, 182, 1830, 1136, 1694, 171, 3488, 120, 172, 11811, 6105, 2042, 3614, 120, 122, 2495, 5822, 2193, 121, 14377, 131, 172, 1204, 170, 1830, 1181, 120, 185, 1883, 9356, 113, 4375, 2373, 118, 136, 7353, 1549, 7368, 1113, 1178, 8682, 119, 119, 119, 114, 1185, 1353, 7125, 1883, 184, 4832, 17993, 119, 2780, 118, 1107, 118, 11769, 7409, 4233, 1107, 1268, 2243, 1105, 20557, 2211, 27645, 117, 20342, 120, 22653, 1107, 2731, 117, 1180, 4248, 1112, 22631, 119, 16516, 16531, 8009, 1197, 8756, 18465, 14229, 117, 1133, 1149, 1104, 10807, 1106, 1353, 20557, 185, 1513, 12602, 174, 3101, 27262, 117, 1336, 4248, 20342, 20994, 1116, 1145, 119, 1126, 20504, 119, 119, 16278, 113, 114, 131, 1103, 1286, 1120, 11077, 1110, 2999, 1107, 2060, 119, 1103, 3555, 1268, 1120, 13119, 2997, 1110, 121, 118, 126, 2608, 1324, 1403, 119, 1286, 21828, 4907, 5552, 2095, 15830, 1279, 1105]\n"
     ]
    }
   ],
   "source": [
    "# # Print the original sentence.\n",
    "# print(' Original: ', sentences[0])\n",
    "\n",
    "# # Print the sentence split into tokens.\n",
    "# print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# # Print the sentence mapped to token ids.\n",
    "# print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeNIc4auFUdF"
   },
   "source": [
    "When we actually convert all of our sentences, we'll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately. \n",
    "\n",
    "Before we can do that, though, we need to talk about some of BERT's formatting requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viKGCCh8izww"
   },
   "source": [
    "## 3.2. Required Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDcqNlvVhL5W"
   },
   "source": [
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "*Side Note: The input format to BERT seems \"over-specified\" to me... We are required to give it a number of pieces of information which seem redundant, or like they could easily be inferred from the data without us explicity providing it. But it is what it is, and I suspect it will make more sense once I have a deeper understanding of the BERT internals.*\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6mceWWOjZnw"
   },
   "source": [
    "### Special Tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykk0P9JiKtVe"
   },
   "source": [
    "\n",
    "**`[SEP]`**\n",
    "\n",
    "At the end of every sentence, we need to append the special `[SEP]` token. \n",
    "\n",
    "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?). \n",
    "\n",
    "I am not certain yet why the token is still required when we have only single-sentence input, but it is!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86C9objaKu8f"
   },
   "source": [
    "**`[CLS]`**\n",
    "\n",
    "For classification tasks, we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
    "\n",
    "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output (but with the feature values changed, of course!).\n",
    "\n",
    "![Illustration of CLS token purpose](https://drive.google.com/uc?export=view&id=1ck4mvGkznVJfW3hv6GUqcdGepVTOx7HE)\n",
    "\n",
    "On the output of the final (12th) transformer, *only the first embedding (corresponding to the [CLS] token) is used by the classifier*.\n",
    "\n",
    ">  \"The first token of every sequence is always a special classification token (`[CLS]`). The final hidden state\n",
    "corresponding to this token is used as the aggregate sequence representation for classification\n",
    "tasks.\" (from the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
    "\n",
    "You might think to try some pooling strategy over the final embeddings, but this isn't necessary. Because BERT is trained to only use this [CLS] token for classification, we know that the model has been motivated to encode everything it needs for the classification step into that single 768-value embedding vector. It's already done the pooling for us!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u51v0kFxeteu"
   },
   "source": [
    "### Sentence Length & Attention Mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPNuwqZVK3T6"
   },
   "source": [
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "1. All sentences must be padded or truncated to a single, fixed length.\n",
    "2. The maximum sentence length is 512 tokens.\n",
    "\n",
    "Padding is done with a special `[PAD]` token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1cb5xeqLu_5vPOgs3eRnail2Y00Fl2pCo\" width=\"600\">\n",
    "\n",
    "The \"Attention Mask\" is simply an array of 1s and 0s indicating which tokens are padding and which aren't (seems kind of redundant, doesn't it?!). This mask tells the \"Self-Attention\" mechanism in BERT not to incorporate these PAD tokens into its interpretation of the sentence.\n",
    "\n",
    "The maximum length does impact training and evaluation speed, however. \n",
    "For example, with a Tesla K80:\n",
    "\n",
    "`MAX_LEN = 128  -->  Training epochs take ~5:28 each`\n",
    "\n",
    "`MAX_LEN = 64   -->  Training epochs take ~2:57 each`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6w8elb-58GJ"
   },
   "source": [
    "## 3.3. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U28qy4P-NwQ9"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
    "\n",
    "1. Split the sentence into tokens.\n",
    "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
    "3. Map the tokens to their IDs.\n",
    "4. Pad or truncate all sentences to the same length.\n",
    "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
    "\n",
    "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKsH2sU0OCQA",
    "outputId": "e363e816-c750-422f-b623-dce428f77502"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from tqdm import trange, tqdm\n",
    "def preprocess_tokenize_embed_data(df_filename):\n",
    "    \n",
    "    '''\n",
    "    Function to use encode_plus to process text data and lables\n",
    "            # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        \n",
    "    input = data file name containing text data/sentences under TEXT column and corresponding labels for classification task\n",
    "    \n",
    "    output = input_ids (encoded sentence id), attention_mask (mask ids for BERT), labels - all converted to tensors\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(df_filename)\n",
    "    \n",
    "    print('Number of sentences: {:,}\\n'.format(df.shape[0]))    \n",
    "\n",
    "    sentences = df.TEXT.values\n",
    "    labels = df.Label.values\n",
    "\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in tqdm(sentences):\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = 512,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    # labels = torch.tensor(labels)\n",
    "    labels = torch.tensor(labels, dtype = torch.long)\n",
    "    # Print sentence 0, now as a list of IDs.\n",
    "    print('Original: ', sentences[0])\n",
    "    print('Token IDs:', input_ids[0])\n",
    "    \n",
    "    # will teturn a TensorDataset using these input_ids, attention_masks and labels\n",
    "    print(\"returning TensorDataset! \")\n",
    "    return TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1M296yz577fV"
   },
   "source": [
    "## 3.4. Training & Validation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to get the train and validation datasets now - will be ready to train on\n",
    "# this will take a bit of time to do so as the tokenization and encoding is quite a lengthy procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tIWAoWL2RK1p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47793 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "  0%|          | 17/47793 [00:00<04:53, 163.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 47,793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47793/47793 [04:42<00:00, 169.34it/s]\n",
      "  0%|          | 17/5774 [00:00<00:34, 168.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  have a significant family history of cancer. occupation: drugs: tobacco: alcohol: other: (per omr): the patient is a previous mechanical engineer. he smoked occasionally but quit 35 years ago. he denies any alcohol use. lives alone and is independent. no close relatives in the area. siblings in . review of systems: flowsheet data as of 10:26 pm vital signs hemodynamic monitoring fluid balance 24 hours since am tmax: 6 c (8 tcurrent: 6 c (8 hr: 106 (106 - 121) bpm bp: 129/59(72) {129/58(72) - 130/59(78)} mmhg rr: 19 (19 - 28) insp/min spo2: 95% heart rhythm: st (sinus tachycardia) total in: 382 ml po: tf: ivf: 7 ml blood products: 375 ml total out: 0 ml 210 ml urine: 210 ml ng: stool: drains: balance: 0 ml 172 ml respiratory o2 delivery device: nasal cannula spo2: 95% physical examination vitals: t: 8 bp:130/70 p:113 r: 18 o2: 97on 4l nc general: alert, oriented, no acute distress heent: sclera anicteric, mmm, oropharynx clear neck: supple, jvp 3cm above clavicle, no lad lungs: wheezes anteriorly with rales at bilateral bases cv: tachycardic, irregularly irregular, no murmurs, rubs, gallops abdomen: soft, non-tender, non-distended, bowel sounds present, no rebound tenderness or guarding, no organomegaly gu: no foley ext: warm, well perfused, edema bilaterally to shins. left foot erythematous, warm, slight ttp labs / radiology fluid analysis / other labs: notable for: hct 6 bnp 6751 ck 39 trop 04 mb not done bun/creatinine 39/1 lactate 0 imaging: ct abd/pelvis (wet read - ? error given comment on only lungs . . .) no small bowel obstruction. tree-in- opacities in right middle and bilateral lower lobes, infectious/inflammatory in nature, could represent aspiration. bibasilar atelectasis, but out of proportion to small bilateral pleural effusions, may represent infectious consolidations also. anemia. . echo (): the left atrium is normal in size. the estimated right atrial pressure is 0-5 mmhg. left ventricular wall thicknesses and\n",
      "Token IDs: tensor([  101,  1138,   170,  2418,  1266,  1607,  1104,  4182,   119,  5846,\n",
      "          131,  5557,   131, 10468,   131,  6272,   131,  1168,   131,   113,\n",
      "         1679,   184,  1306,  1197,   114,   131,  1103,  5351,  1110,   170,\n",
      "         2166,  6676,  3806,   119,  1119, 23235,  5411,  1133,  8204,  2588,\n",
      "         1201,  2403,   119,  1119, 26360,  1251,  6272,  1329,   119,  2491,\n",
      "         2041,  1105,  1110,  2457,   119,  1185,  1601,  8908,  1107,  1103,\n",
      "         1298,   119,  9302,  1107,   119,  3189,  1104,  2344,   131,  5611,\n",
      "        19989,  1204,  2233,  1112,  1104,  1275,   131,  1744,  9852,  9301,\n",
      "         5300, 23123, 22320, 12881,  1596,  9437,  8240,  5233,  1572,  2005,\n",
      "         1290,  1821,   189, 22871,   131,   127,   172,   113,   129,   189,\n",
      "        21754,   131,   127,   172,   113,   129,   177,  1197,   131,  9920,\n",
      "          113,  9920,   118, 12794,   114,   171,  9952,   171,  1643,   131,\n",
      "        14949,   120,  4589,   113,  5117,   114,   196, 14949,   120,  4650,\n",
      "          113,  5117,   114,   118,  7029,   120,  4589,   113,  5603,   114,\n",
      "          198,  2608,  1324,  1403,   187,  1197,   131,  1627,   113,  1627,\n",
      "          118,  1743,   114, 22233,  1643,   120, 11241,   188,  5674,  1477,\n",
      "          131,  4573,   110,  1762,  6795,   131,   188,  1204,   113, 11850,\n",
      "         1361, 27629,  8992, 10542,  1465,   114,  1703,  1107,   131,  3383,\n",
      "         1477,   182,  1233,   185,  1186,   131,   189,  2087,   131,   178,\n",
      "         1964,  2087,   131,   128,   182,  1233,  1892,  2982,   131, 19397,\n",
      "          182,  1233,  1703,  1149,   131,   121,   182,  1233, 13075,   182,\n",
      "         1233, 19968,   131, 13075,   182,  1233, 21174,   131, 15631,   131,\n",
      "        20681,   131,  5233,   131,   121,   182,  1233, 19639,   182,  1233,\n",
      "        19192,   184,  1477,  6779,  4442,   131, 21447,  1169, 14787,  1742,\n",
      "          188,  5674,  1477,   131,  4573,   110,  2952,  8179,  9301,  1116,\n",
      "          131,   189,   131,   129,   171,  1643,   131,  7029,   120,  3102,\n",
      "          185,   131, 12206,   187,   131,  1407,   184,  1477,   131,  5311,\n",
      "         1320,   125,  1233,   183,  1665,  1704,   131, 10427,   117,  7779,\n",
      "          117,  1185, 12104, 13632,  1119,  3452,   131,   188, 10536,  1611,\n",
      "         1126, 17882, 26237,   117,  2608,  1306,   117,  1137,  4184,  7111,\n",
      "        22093,  2330,  2455,   131, 28117,  8661,  1513,   117,   179,  1964,\n",
      "         1643,   124,  1665,  1306,  1807,   172,  9516, 26726,   117,  1185,\n",
      "        19122,  8682,   131,   192, 19989, 11846, 16557,  1193,  1114,   187,\n",
      "        19856,  1120, 20557,  7616,   172,  1964,   131, 27629,  8992, 10542,\n",
      "         1596,   117, 12692,  1193, 12692,   117,  1185, 26792,   117, 16259,\n",
      "         1116,   117, 20003, 22101, 14701,   131,  2991,   117,  1664,   118,\n",
      "         8886,   117,  1664,   118,  4267, 15874,  4902,   117,  7125,  1883,\n",
      "         3807,  1675,   117,  1185,  1231,  8346,  8886,  1757,  1137, 18648,\n",
      "          117,  1185,  5677,  6758,  6997,  1183,   176,  1358,   131,  1185,\n",
      "          175,  9016,  1183,  4252,  1204,   131,  3258,   117,  1218,  1679,\n",
      "        21089,   117,  5048, 14494, 20557,  1193,  1106,   188,  8265,  1116,\n",
      "          119,  1286,  2555, 14044, 25669, 15391, 10024,  1361,   117,  3258,\n",
      "          117,  6812,   189,  1204,  1643, 21973,   120,  2070,  6360,  8240,\n",
      "         3622,   120,  1168, 21973,   131,  3385,  1111,   131,   177,  5822,\n",
      "          127,   171,  1179,  1643,  5486, 24050,   172,  1377,  3614,   189,\n",
      "        12736,  5129,   182,  1830,  1136,  1694,   171,  3488,   120,   172,\n",
      "        11811,  6105,  2042,  3614,   120,   122,  2495,  5822,  2193,   121,\n",
      "        14377,   131,   172,  1204,   170,  1830,  1181,   120,   185,  1883,\n",
      "         9356,   113,  4375,  2373,   118,   136,  7353,  1549,  7368,  1113,\n",
      "         1178,  8682,   119,   119,   119,   114,  1185,  1353,  7125,  1883,\n",
      "          184,  4832, 17993,   119,  2780,   118,  1107,   118, 11769,  7409,\n",
      "         4233,   102])\n",
      "returning TensorDataset! \n",
      "Number of sentences: 5,774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5774/5774 [00:33<00:00, 170.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  10:11 pm chest (pre-op pa & lat) clip # reason: coronary artery disease admitting diagnosis: coronary artery disease medical condition: 77 year old woman with reason for this examination: pre-op final report indication: 77 year old pre-op for cabg. technique: pa and lateral radiographs. comparison: findings: the heart is enlarged. there are bilateral pleural effusions, right greater than left with associated minor atelectatic changes at the lung bases. the pulmonary vasculature appears somewhat prominent with an upper zone redistribution. there is no pneumothorax. the patient has had a prior cabg with unchanged appearance of median sternotomy wires. surgical clips are also seen overlying both right and left hemithoraces. the osseous structures are unremarkable. impression: cardiomegaly with mild congestive heart failure and bilateral pleural effusions. patient/test information: indication: aortic valve disease. coronary artery disease. height: (in) 65 weight (lb): 198 bsa (m2): 97 m2 bp (mm hg): 140/74 hr (bpm): 50 status: inpatient date/time: at 10:53 test: tte (complete) doppler: full doppler and color doppler contrast: none technical quality: adequate interpretation: findings: left atrium: mild la enlargement. right atrium/interatrial septum: mildly dilated ra. left ventricle: mild symmetric lvh. mildly dilated lv cavity. mild regional lv systolic dysfunction. no resting lvot gradient. no lv mass/thrombus. lv wall motion: regional lv wall motion abnormalities include: septal apex - hypo; apex - dyskinetic; right ventricle: normal rv chamber size and free wall motion. aorta: normal aortic root diameter. moderately dilated ascending aorta. aortic valve: severely thickened/deformed aortic valve leaflets. moderate as. mitral valve: mildly thickened mitral valve leaflets. mild mitral annular calcification. mild thickening of mitral valve chordae. mild (1+) mr. tricuspid valve: mild pa systolic hypertension. pericardium: no pericardial effusion. general comments: suboptimal image quality - poor subcostal views. based on aha endocarditis prophylaxis recommendations, the echo findings indicate a moderate risk (prophylaxis recommended). clinical decisions regarding the need for prophylaxis should be based on clinical and echocardiographic data. right pleural\n",
      "Token IDs: tensor([  101,  1275,   131,  1429,  9852,  2229,   113,  3073,   118, 11769,\n",
      "          185,  1161,   111,  2495,  1204,   114, 13500,   108,  2255,   131,\n",
      "         1884, 15789,  1616, 18593,  3653, 19931, 12645,   131,  1884, 15789,\n",
      "         1616, 18593,  3653,  2657,  3879,   131,  5581,  1214,  1385,  1590,\n",
      "         1114,  2255,  1111,  1142,  8179,   131,  3073,   118, 11769,  1509,\n",
      "         2592, 12754,   131,  5581,  1214,  1385,  3073,   118, 11769,  1111,\n",
      "        10347,  1403,   119,  5531,   131,   185,  1161,  1105, 11937,  2070,\n",
      "        21217,   119,  7577,   131,  9505,   131,  1103,  1762,  1110, 12089,\n",
      "          119,  1175,  1132, 20557,   185,  1513, 12602,   174,  3101, 27262,\n",
      "          117,  1268,  3407,  1190,  1286,  1114,  2628,  3137,  8756, 18465,\n",
      "         7698,  2607,  1120,  1103, 13093,  7616,   119,  1103, 26600,   191,\n",
      "         2225, 21608,  5332,  2691,  4742,  3289,  1114,  1126,  3105,  4834,\n",
      "         1894,  1776,  2047, 16442,  1988,   119,  1175,  1110,  1185,   185,\n",
      "         1673,  1818, 12858, 25632,   119,  1103,  5351,  1144,  1125,   170,\n",
      "         2988, 10347,  1403,  1114, 16684,  2468,  1104,  3151, 12172, 12355,\n",
      "         4527, 15923,   119, 13467, 16973,  1132,  1145,  1562, 16201,  1158,\n",
      "         1241,  1268,  1105,  1286, 23123,  7088,  6533,  7723,   119,  1103,\n",
      "          184, 11553,  2285,  4413,  1132,  8362, 16996, 23822,  1895,   119,\n",
      "         8351,   131,  3621,  2660,  3263,  6997,  1183,  1114, 10496, 14255,\n",
      "         7562,  3946,  1762,  4290,  1105, 20557,   185,  1513, 12602,   174,\n",
      "         3101, 27262,   119,  5351,   120,  2774,  1869,   131, 12754,   131,\n",
      "          170, 12148,  1596, 11727,  3653,   119,  1884, 15789,  1616, 18593,\n",
      "         3653,   119,  3976,   131,   113,  1107,   114,  2625,  2841,   113,\n",
      "         5682,   114,   131, 21801,   171,  3202,   113,   182,  1477,   114,\n",
      "          131,  5311,   182,  1477,   171,  1643,   113,  2608,   177,  1403,\n",
      "          114,   131,  8183,   120,  5692,   177,  1197,   113,   171,  9952,\n",
      "          114,   131,  1851,  2781,   131,  1107, 27420,  2236,   120,  1159,\n",
      "          131,  1120,  1275,   131,  4389,  2774,   131,   189,  1566,   113,\n",
      "         2335,   114,  1202,  8661,  2879,   131,  1554,  1202,  8661,  2879,\n",
      "         1105,  2942,  1202,  8661,  2879,  5014,   131,  3839,  4301,  3068,\n",
      "          131, 12373,  7628,   131,  9505,   131,  1286,  1120, 11077,   131,\n",
      "        10496,  2495,  4035,  5815, 20512,   119,  1268,  1120, 11077,   120,\n",
      "         9455,  2980, 13119, 14516,  6451,  1818,   131, 21461,  4267,  6951,\n",
      "          187,  1161,   119,  1286, 21828,  4907,  1513,   131, 10496, 21852,\n",
      "          181,  1964,  1324,   119, 21461,  4267,  6951,   181,  1964, 19421,\n",
      "          119, 10496,  2918,   181,  1964,   188,  6834,  2430,  8031,   173,\n",
      "         6834, 26420,   119,  1185,  8137,   181,  6005,  1204, 19848,   119,\n",
      "         1185,   181,  1964,  3367,   120, 24438, 16071,  7441,   119,   181,\n",
      "         1964,  2095,  4018,   131,  2918,   181,  1964,  2095,  4018, 22832,\n",
      "         4233,  1511,   131, 14516, 21919,  1233, 15764,   118,   177,  1183,\n",
      "         5674,   132, 15764,   118,   173,  6834,  4314,  9265,   132,  1268,\n",
      "        21828,  4907,  1513,   131,  2999,   187,  1964,  5383,  2060,  1105,\n",
      "         1714,  2095,  4018,   119,   170, 12148,  1161,   131,  2999,   170,\n",
      "        12148,  1596,  7261,  6211,   119, 19455,  4267,  6951, 26457,   170,\n",
      "        12148,  1161,   119,   170, 12148,  1596, 11727,   131,  8669,  3528,\n",
      "         4772,   120, 19353, 24211,  1174,   170, 12148,  1596, 11727,  7404,\n",
      "         9585,   119,  8828,  1112,   119, 26410,  4412, 11727,   131, 21461,\n",
      "         3528,  4772, 26410,  4412, 11727,  7404,  9585,   119, 10496, 26410,\n",
      "         4412,  1126, 14787,  5815, 11019,  1233,  6617, 11531,   119, 10496,\n",
      "         3528,  4777,  1104, 26410,  4412, 11727, 15461,  5024,   119, 10496,\n",
      "          113,   122,   116,   114,   182,  1197,   119,   189,  4907,  1361,\n",
      "        25786,   102])\n",
      "returning TensorDataset! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = preprocess_tokenize_embed_data(\"./data/discharge/train.csv\")\n",
    "val_dataset =  preprocess_tokenize_embed_data(\"./data/3discharge/val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47793"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD9i6Z2pG-sN"
   },
   "source": [
    "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XGUqOCtgqGhP"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n",
      "torch.int64\n",
      "torch.Size([16, 512])\n",
      "torch.int64\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# little test to see correct shapes of train and val datasets\n",
    "\n",
    "# For each batch of training data...\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "    # `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    \n",
    "    print(b_input_ids.dtype)\n",
    "    print(b_input_ids.shape)\n",
    "    print(b_labels.dtype)\n",
    "    print(b_labels.shape)\n",
    "    \n",
    "    # stop after 10 batches.\n",
    "    if step % 10 == 0 and not step == 0:\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bwa6Rts-02-"
   },
   "source": [
    "# 4. Train Our Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xYQ3iLO08SX"
   },
   "source": [
    "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6TKgyUzPIQc"
   },
   "source": [
    "## 4.1. BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sjzRT1V0zwm"
   },
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXYitPoE-cjH"
   },
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnQW9E-bBCRt"
   },
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "bf9dfa1ff3e642fbb74c5146d21044c2",
      "1c2b0ede959142fc89bf07a9c88df638",
      "1296a3d754b344a482a03e5af84e805e",
      "6f132d7bb83d41b6847df0d0ec0a1b92",
      "2755b9838bae408ca8cf667ad9d501fc",
      "f8874fec8a404ae89a38fd2ecbb357cf",
      "a7bdbedc75de4f77b45f1389c2ea0abc",
      "978c24b18b594eaf8ca47730a88eefb9",
      "fe254c3bcc08402eb506f0e98f5673a7",
      "cea84f9c3db641acb98314028b305514",
      "23ca9359e6c44232a1346e6f2ab7e48c",
      "d689bc8d488a4dc09c393b4fc9747bcb",
      "6c7dec7b1e804c2195f6e60fb3c1d18e",
      "0fe5b1d0540240a8a8426352c24b2887",
      "4b1e27aff6f04fec8268d951e46b1e63",
      "440da34c72344cb08e4a1ee5de7049ee"
     ]
    },
    "id": "gFsCTp_mporB",
    "outputId": "af690f33-6cd5-4678-bdaf-209f068f70f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "#                     # You can increase this for multi-class tasks.   \n",
    "#     output_attentions = False, # Whether the model returns attentions weights.\n",
    "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "# )\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "#set whether we want to freeze all layers other than the new classifier layer\n",
    "do_freezing = True\n",
    "if do_freezing:\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'classifier' not in name: # classifier layer\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0140, -0.0392, -0.0104,  ..., -0.0048, -0.0111, -0.0036],\n",
      "        [ 0.0318, -0.0003,  0.0041,  ..., -0.0078,  0.0085, -0.0164]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# or load original clinicalBERT pretraining model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     \"./model/pretraining/\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "#                     # You can increase this for multi-class tasks.   \n",
    "#     output_attentions = False, # Whether the model returns attentions weights.\n",
    "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "# )\n",
    "\n",
    "# # Tell pytorch to run this model on the GPU.\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0Jv6c7-HHDW"
   },
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PIiVlDYCtSq",
    "outputId": "7430f38d-de86-4488-bb92-6a9b0142b3af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (28996, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRWT-D4U_Pvx"
   },
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o-VEBobKwHk"
   },
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2e-05\n"
     ]
    }
   ],
   "source": [
    "# no_decay = ['bias', 'gamma', 'beta']\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "#     {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "#     ]\n",
    "# optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "#                      lr=learning_rate,\n",
    "#                      warmup=warmup_proportion,\n",
    "#                      t_total=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GLs72DuMODJO"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
    "                    correct_bias = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-p0upAhhRiIx"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqfmWwUR_Sox"
   },
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QXZhFb4LnV5"
   },
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE5B99H5H2-W"
   },
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9cQNvaZ9bnyy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNhRtWPXH9C3"
   },
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gpt6tR83keZD"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfNIhN19te3N"
   },
   "source": [
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell below is for training the classifier with 2 labels/outputsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J-FYdx6nFE_",
    "outputId": "b2c3e30b-eb5d-4b13-a207-05a48a87ed2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  1,494.    Elapsed: 0:02:49.\n",
      "  Batch 1,000  of  1,494.    Elapsed: 0:05:40.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/181 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:08:28\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/181 [00:00<00:57,  3.11it/s]\u001b[A\n",
      "  1%|          | 2/181 [00:00<00:57,  3.11it/s]\u001b[A\n",
      "  2%|▏         | 3/181 [00:00<00:57,  3.11it/s]\u001b[A\n",
      "  2%|▏         | 4/181 [00:01<00:56,  3.11it/s]\u001b[A\n",
      "  3%|▎         | 5/181 [00:01<00:56,  3.10it/s]\u001b[A\n",
      "  3%|▎         | 6/181 [00:01<00:56,  3.10it/s]\u001b[A\n",
      "  4%|▍         | 7/181 [00:02<00:55,  3.11it/s]\u001b[A\n",
      "  4%|▍         | 8/181 [00:02<00:55,  3.11it/s]\u001b[A\n",
      "  5%|▍         | 9/181 [00:02<00:55,  3.11it/s]\u001b[A\n",
      "  6%|▌         | 10/181 [00:03<00:55,  3.10it/s]\u001b[A\n",
      "  6%|▌         | 11/181 [00:03<00:54,  3.11it/s]\u001b[A\n",
      "  7%|▋         | 12/181 [00:03<00:54,  3.11it/s]\u001b[A\n",
      "  7%|▋         | 13/181 [00:04<00:54,  3.11it/s]\u001b[A\n",
      "  8%|▊         | 14/181 [00:04<00:53,  3.11it/s]\u001b[A\n",
      "  8%|▊         | 15/181 [00:04<00:53,  3.11it/s]\u001b[A\n",
      "  9%|▉         | 16/181 [00:05<00:53,  3.10it/s]\u001b[A\n",
      "  9%|▉         | 17/181 [00:05<00:52,  3.10it/s]\u001b[A\n",
      " 10%|▉         | 18/181 [00:05<00:52,  3.11it/s]\u001b[A\n",
      " 10%|█         | 19/181 [00:06<00:52,  3.11it/s]\u001b[A\n",
      " 11%|█         | 20/181 [00:06<00:51,  3.11it/s]\u001b[A\n",
      " 12%|█▏        | 21/181 [00:06<00:51,  3.12it/s]\u001b[A\n",
      " 12%|█▏        | 22/181 [00:07<00:51,  3.11it/s]\u001b[A\n",
      " 13%|█▎        | 23/181 [00:07<00:50,  3.12it/s]\u001b[A\n",
      " 13%|█▎        | 24/181 [00:07<00:50,  3.12it/s]\u001b[A\n",
      " 14%|█▍        | 25/181 [00:08<00:50,  3.11it/s]\u001b[A\n",
      " 14%|█▍        | 26/181 [00:08<00:49,  3.11it/s]\u001b[A\n",
      " 15%|█▍        | 27/181 [00:08<00:49,  3.11it/s]\u001b[A\n",
      " 15%|█▌        | 28/181 [00:09<00:49,  3.11it/s]\u001b[A\n",
      " 16%|█▌        | 29/181 [00:09<00:48,  3.11it/s]\u001b[A\n",
      " 17%|█▋        | 30/181 [00:09<00:48,  3.10it/s]\u001b[A\n",
      " 17%|█▋        | 31/181 [00:09<00:48,  3.10it/s]\u001b[A\n",
      " 18%|█▊        | 32/181 [00:10<00:48,  3.10it/s]\u001b[A\n",
      " 18%|█▊        | 33/181 [00:10<00:47,  3.10it/s]\u001b[A\n",
      " 19%|█▉        | 34/181 [00:10<00:47,  3.11it/s]\u001b[A\n",
      " 19%|█▉        | 35/181 [00:11<00:46,  3.11it/s]\u001b[A\n",
      " 20%|█▉        | 36/181 [00:11<00:46,  3.11it/s]\u001b[A\n",
      " 20%|██        | 37/181 [00:11<00:46,  3.11it/s]\u001b[A\n",
      " 21%|██        | 38/181 [00:12<00:46,  3.11it/s]\u001b[A\n",
      " 22%|██▏       | 39/181 [00:12<00:45,  3.10it/s]\u001b[A\n",
      " 22%|██▏       | 40/181 [00:12<00:45,  3.10it/s]\u001b[A\n",
      " 23%|██▎       | 41/181 [00:13<00:45,  3.11it/s]\u001b[A\n",
      " 23%|██▎       | 42/181 [00:13<00:44,  3.11it/s]\u001b[A\n",
      " 24%|██▍       | 43/181 [00:13<00:44,  3.11it/s]\u001b[A\n",
      " 24%|██▍       | 44/181 [00:14<00:44,  3.11it/s]\u001b[A\n",
      " 25%|██▍       | 45/181 [00:14<00:43,  3.11it/s]\u001b[A\n",
      " 25%|██▌       | 46/181 [00:14<00:43,  3.11it/s]\u001b[A\n",
      " 26%|██▌       | 47/181 [00:15<00:43,  3.11it/s]\u001b[A\n",
      " 27%|██▋       | 48/181 [00:15<00:42,  3.11it/s]\u001b[A\n",
      " 27%|██▋       | 49/181 [00:15<00:42,  3.11it/s]\u001b[A\n",
      " 28%|██▊       | 50/181 [00:16<00:42,  3.11it/s]\u001b[A\n",
      " 28%|██▊       | 51/181 [00:16<00:41,  3.11it/s]\u001b[A\n",
      " 29%|██▊       | 52/181 [00:16<00:41,  3.11it/s]\u001b[A\n",
      " 29%|██▉       | 53/181 [00:17<00:41,  3.11it/s]\u001b[A\n",
      " 30%|██▉       | 54/181 [00:17<00:40,  3.11it/s]\u001b[A\n",
      " 30%|███       | 55/181 [00:17<00:40,  3.11it/s]\u001b[A\n",
      " 31%|███       | 56/181 [00:18<00:40,  3.11it/s]\u001b[A\n",
      " 31%|███▏      | 57/181 [00:18<00:39,  3.11it/s]\u001b[A\n",
      " 32%|███▏      | 58/181 [00:18<00:39,  3.11it/s]\u001b[A\n",
      " 33%|███▎      | 59/181 [00:18<00:39,  3.11it/s]\u001b[A\n",
      " 33%|███▎      | 60/181 [00:19<00:38,  3.11it/s]\u001b[A\n",
      " 34%|███▎      | 61/181 [00:19<00:38,  3.11it/s]\u001b[A\n",
      " 34%|███▍      | 62/181 [00:19<00:38,  3.11it/s]\u001b[A\n",
      " 35%|███▍      | 63/181 [00:20<00:37,  3.11it/s]\u001b[A\n",
      " 35%|███▌      | 64/181 [00:20<00:37,  3.10it/s]\u001b[A\n",
      " 36%|███▌      | 65/181 [00:20<00:37,  3.11it/s]\u001b[A\n",
      " 36%|███▋      | 66/181 [00:21<00:37,  3.11it/s]\u001b[A\n",
      " 37%|███▋      | 67/181 [00:21<00:36,  3.11it/s]\u001b[A\n",
      " 38%|███▊      | 68/181 [00:21<00:36,  3.11it/s]\u001b[A\n",
      " 38%|███▊      | 69/181 [00:22<00:36,  3.11it/s]\u001b[A\n",
      " 39%|███▊      | 70/181 [00:22<00:35,  3.11it/s]\u001b[A\n",
      " 39%|███▉      | 71/181 [00:22<00:35,  3.11it/s]\u001b[A\n",
      " 40%|███▉      | 72/181 [00:23<00:34,  3.11it/s]\u001b[A\n",
      " 40%|████      | 73/181 [00:23<00:34,  3.12it/s]\u001b[A\n",
      " 41%|████      | 74/181 [00:23<00:34,  3.12it/s]\u001b[A\n",
      " 41%|████▏     | 75/181 [00:24<00:34,  3.12it/s]\u001b[A\n",
      " 42%|████▏     | 76/181 [00:24<00:33,  3.12it/s]\u001b[A\n",
      " 43%|████▎     | 77/181 [00:24<00:33,  3.11it/s]\u001b[A\n",
      " 43%|████▎     | 78/181 [00:25<00:33,  3.11it/s]\u001b[A\n",
      " 44%|████▎     | 79/181 [00:25<00:32,  3.11it/s]\u001b[A\n",
      " 44%|████▍     | 80/181 [00:25<00:32,  3.11it/s]\u001b[A\n",
      " 45%|████▍     | 81/181 [00:26<00:32,  3.11it/s]\u001b[A\n",
      " 45%|████▌     | 82/181 [00:26<00:31,  3.11it/s]\u001b[A\n",
      " 46%|████▌     | 83/181 [00:26<00:31,  3.11it/s]\u001b[A\n",
      " 46%|████▋     | 84/181 [00:27<00:31,  3.11it/s]\u001b[A\n",
      " 47%|████▋     | 85/181 [00:27<00:30,  3.11it/s]\u001b[A\n",
      " 48%|████▊     | 86/181 [00:27<00:30,  3.11it/s]\u001b[A\n",
      " 48%|████▊     | 87/181 [00:27<00:30,  3.11it/s]\u001b[A\n",
      " 49%|████▊     | 88/181 [00:28<00:29,  3.11it/s]\u001b[A\n",
      " 49%|████▉     | 89/181 [00:28<00:29,  3.11it/s]\u001b[A\n",
      " 50%|████▉     | 90/181 [00:28<00:29,  3.11it/s]\u001b[A\n",
      " 50%|█████     | 91/181 [00:29<00:28,  3.11it/s]\u001b[A\n",
      " 51%|█████     | 92/181 [00:29<00:28,  3.11it/s]\u001b[A\n",
      " 51%|█████▏    | 93/181 [00:29<00:28,  3.11it/s]\u001b[A\n",
      " 52%|█████▏    | 94/181 [00:30<00:27,  3.11it/s]\u001b[A\n",
      " 52%|█████▏    | 95/181 [00:30<00:27,  3.11it/s]\u001b[A\n",
      " 53%|█████▎    | 96/181 [00:30<00:27,  3.11it/s]\u001b[A\n",
      " 54%|█████▎    | 97/181 [00:31<00:26,  3.11it/s]\u001b[A\n",
      " 54%|█████▍    | 98/181 [00:31<00:26,  3.11it/s]\u001b[A\n",
      " 55%|█████▍    | 99/181 [00:31<00:26,  3.11it/s]\u001b[A\n",
      " 55%|█████▌    | 100/181 [00:32<00:26,  3.11it/s]\u001b[A\n",
      " 56%|█████▌    | 101/181 [00:32<00:25,  3.11it/s]\u001b[A\n",
      " 56%|█████▋    | 102/181 [00:32<00:25,  3.11it/s]\u001b[A\n",
      " 57%|█████▋    | 103/181 [00:33<00:25,  3.11it/s]\u001b[A\n",
      " 57%|█████▋    | 104/181 [00:33<00:24,  3.11it/s]\u001b[A\n",
      " 58%|█████▊    | 105/181 [00:33<00:24,  3.11it/s]\u001b[A\n",
      " 59%|█████▊    | 106/181 [00:34<00:24,  3.10it/s]\u001b[A\n",
      " 59%|█████▉    | 107/181 [00:34<00:23,  3.10it/s]\u001b[A\n",
      " 60%|█████▉    | 108/181 [00:34<00:23,  3.11it/s]\u001b[A\n",
      " 60%|██████    | 109/181 [00:35<00:23,  3.11it/s]\u001b[A\n",
      " 61%|██████    | 110/181 [00:35<00:22,  3.11it/s]\u001b[A\n",
      " 61%|██████▏   | 111/181 [00:35<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 112/181 [00:36<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 113/181 [00:36<00:21,  3.10it/s]\u001b[A\n",
      " 63%|██████▎   | 114/181 [00:36<00:21,  3.11it/s]\u001b[A\n",
      " 64%|██████▎   | 115/181 [00:36<00:21,  3.11it/s]\u001b[A\n",
      " 64%|██████▍   | 116/181 [00:37<00:20,  3.11it/s]\u001b[A\n",
      " 65%|██████▍   | 117/181 [00:37<00:20,  3.11it/s]\u001b[A\n",
      " 65%|██████▌   | 118/181 [00:37<00:20,  3.10it/s]\u001b[A\n",
      " 66%|██████▌   | 119/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 66%|██████▋   | 120/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 67%|██████▋   | 121/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 67%|██████▋   | 122/181 [00:39<00:18,  3.11it/s]\u001b[A\n",
      " 68%|██████▊   | 123/181 [00:39<00:18,  3.11it/s]\u001b[A\n",
      " 69%|██████▊   | 124/181 [00:39<00:18,  3.11it/s]\u001b[A\n",
      " 69%|██████▉   | 125/181 [00:40<00:18,  3.11it/s]\u001b[A\n",
      " 70%|██████▉   | 126/181 [00:40<00:17,  3.11it/s]\u001b[A\n",
      " 70%|███████   | 127/181 [00:40<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████   | 128/181 [00:41<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████▏  | 129/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 130/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 131/181 [00:42<00:16,  3.10it/s]\u001b[A\n",
      " 73%|███████▎  | 132/181 [00:42<00:15,  3.11it/s]\u001b[A\n",
      " 73%|███████▎  | 133/181 [00:42<00:15,  3.11it/s]\u001b[A\n",
      " 74%|███████▍  | 134/181 [00:43<00:15,  3.10it/s]\u001b[A\n",
      " 75%|███████▍  | 135/181 [00:43<00:14,  3.11it/s]\u001b[A\n",
      " 75%|███████▌  | 136/181 [00:43<00:14,  3.11it/s]\u001b[A\n",
      " 76%|███████▌  | 137/181 [00:44<00:14,  3.11it/s]\u001b[A\n",
      " 76%|███████▌  | 138/181 [00:44<00:13,  3.11it/s]\u001b[A\n",
      " 77%|███████▋  | 139/181 [00:44<00:13,  3.11it/s]\u001b[A\n",
      " 77%|███████▋  | 140/181 [00:45<00:13,  3.11it/s]\u001b[A\n",
      " 78%|███████▊  | 141/181 [00:45<00:12,  3.11it/s]\u001b[A\n",
      " 78%|███████▊  | 142/181 [00:45<00:12,  3.10it/s]\u001b[A\n",
      " 79%|███████▉  | 143/181 [00:46<00:12,  3.10it/s]\u001b[A\n",
      " 80%|███████▉  | 144/181 [00:46<00:11,  3.10it/s]\u001b[A\n",
      " 80%|████████  | 145/181 [00:46<00:11,  3.10it/s]\u001b[A\n",
      " 81%|████████  | 146/181 [00:46<00:11,  3.10it/s]\u001b[A\n",
      " 81%|████████  | 147/181 [00:47<00:10,  3.10it/s]\u001b[A\n",
      " 82%|████████▏ | 148/181 [00:47<00:10,  3.11it/s]\u001b[A\n",
      " 82%|████████▏ | 149/181 [00:47<00:10,  3.11it/s]\u001b[A\n",
      " 83%|████████▎ | 150/181 [00:48<00:09,  3.11it/s]\u001b[A\n",
      " 83%|████████▎ | 151/181 [00:48<00:09,  3.10it/s]\u001b[A\n",
      " 84%|████████▍ | 152/181 [00:48<00:09,  3.10it/s]\u001b[A\n",
      " 85%|████████▍ | 153/181 [00:49<00:09,  3.10it/s]\u001b[A\n",
      " 85%|████████▌ | 154/181 [00:49<00:08,  3.10it/s]\u001b[A\n",
      " 86%|████████▌ | 155/181 [00:49<00:08,  3.10it/s]\u001b[A\n",
      " 86%|████████▌ | 156/181 [00:50<00:08,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 157/181 [00:50<00:07,  3.10it/s]\u001b[A\n",
      " 87%|████████▋ | 158/181 [00:50<00:07,  3.11it/s]\u001b[A\n",
      " 88%|████████▊ | 159/181 [00:51<00:07,  3.11it/s]\u001b[A\n",
      " 88%|████████▊ | 160/181 [00:51<00:06,  3.11it/s]\u001b[A\n",
      " 89%|████████▉ | 161/181 [00:51<00:06,  3.10it/s]\u001b[A\n",
      " 90%|████████▉ | 162/181 [00:52<00:06,  3.10it/s]\u001b[A\n",
      " 90%|█████████ | 163/181 [00:52<00:05,  3.10it/s]\u001b[A\n",
      " 91%|█████████ | 164/181 [00:52<00:05,  3.10it/s]\u001b[A\n",
      " 91%|█████████ | 165/181 [00:53<00:05,  3.10it/s]\u001b[A\n",
      " 92%|█████████▏| 166/181 [00:53<00:04,  3.10it/s]\u001b[A\n",
      " 92%|█████████▏| 167/181 [00:53<00:04,  3.10it/s]\u001b[A\n",
      " 93%|█████████▎| 168/181 [00:54<00:04,  3.10it/s]\u001b[A\n",
      " 93%|█████████▎| 169/181 [00:54<00:03,  3.11it/s]\u001b[A\n",
      " 94%|█████████▍| 170/181 [00:54<00:03,  3.10it/s]\u001b[A\n",
      " 94%|█████████▍| 171/181 [00:55<00:03,  3.10it/s]\u001b[A\n",
      " 95%|█████████▌| 172/181 [00:55<00:02,  3.10it/s]\u001b[A\n",
      " 96%|█████████▌| 173/181 [00:55<00:02,  3.10it/s]\u001b[A\n",
      " 96%|█████████▌| 174/181 [00:55<00:02,  3.10it/s]\u001b[A\n",
      " 97%|█████████▋| 175/181 [00:56<00:01,  3.10it/s]\u001b[A\n",
      " 97%|█████████▋| 176/181 [00:56<00:01,  3.11it/s]\u001b[A\n",
      " 98%|█████████▊| 177/181 [00:56<00:01,  3.11it/s]\u001b[A\n",
      " 98%|█████████▊| 178/181 [00:57<00:00,  3.11it/s]\u001b[A\n",
      " 99%|█████████▉| 179/181 [00:57<00:00,  3.11it/s]\u001b[A\n",
      " 99%|█████████▉| 180/181 [00:57<00:00,  3.11it/s]\u001b[A\n",
      "100%|██████████| 181/181 [00:58<00:00,  3.12it/s]\u001b[A\n",
      "Epoch:  25%|██▌       | 1/4 [09:26<28:18, 566.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.54\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  1,494.    Elapsed: 0:02:51.\n",
      "  Batch 1,000  of  1,494.    Elapsed: 0:05:42.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/181 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:08:30\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/181 [00:00<00:57,  3.12it/s]\u001b[A\n",
      "  1%|          | 2/181 [00:00<00:57,  3.11it/s]\u001b[A\n",
      "  2%|▏         | 3/181 [00:00<00:57,  3.10it/s]\u001b[A\n",
      "  2%|▏         | 4/181 [00:01<00:56,  3.11it/s]\u001b[A\n",
      "  3%|▎         | 5/181 [00:01<00:56,  3.10it/s]\u001b[A\n",
      "  3%|▎         | 6/181 [00:01<00:56,  3.10it/s]\u001b[A\n",
      "  4%|▍         | 7/181 [00:02<00:56,  3.10it/s]\u001b[A\n",
      "  4%|▍         | 8/181 [00:02<00:55,  3.10it/s]\u001b[A\n",
      "  5%|▍         | 9/181 [00:02<00:55,  3.10it/s]\u001b[A\n",
      "  6%|▌         | 10/181 [00:03<00:55,  3.10it/s]\u001b[A\n",
      "  6%|▌         | 11/181 [00:03<00:54,  3.10it/s]\u001b[A\n",
      "  7%|▋         | 12/181 [00:03<00:54,  3.10it/s]\u001b[A\n",
      "  7%|▋         | 13/181 [00:04<00:54,  3.10it/s]\u001b[A\n",
      "  8%|▊         | 14/181 [00:04<00:53,  3.10it/s]\u001b[A\n",
      "  8%|▊         | 15/181 [00:04<00:53,  3.11it/s]\u001b[A\n",
      "  9%|▉         | 16/181 [00:05<00:53,  3.10it/s]\u001b[A\n",
      "  9%|▉         | 17/181 [00:05<00:52,  3.10it/s]\u001b[A\n",
      " 10%|▉         | 18/181 [00:05<00:52,  3.10it/s]\u001b[A\n",
      " 10%|█         | 19/181 [00:06<00:52,  3.10it/s]\u001b[A\n",
      " 11%|█         | 20/181 [00:06<00:51,  3.10it/s]\u001b[A\n",
      " 12%|█▏        | 21/181 [00:06<00:51,  3.10it/s]\u001b[A\n",
      " 12%|█▏        | 22/181 [00:07<00:51,  3.10it/s]\u001b[A\n",
      " 13%|█▎        | 23/181 [00:07<00:50,  3.10it/s]\u001b[A\n",
      " 13%|█▎        | 24/181 [00:07<00:50,  3.11it/s]\u001b[A\n",
      " 14%|█▍        | 25/181 [00:08<00:50,  3.11it/s]\u001b[A\n",
      " 14%|█▍        | 26/181 [00:08<00:49,  3.11it/s]\u001b[A\n",
      " 15%|█▍        | 27/181 [00:08<00:49,  3.11it/s]\u001b[A\n",
      " 15%|█▌        | 28/181 [00:09<00:49,  3.11it/s]\u001b[A\n",
      " 16%|█▌        | 29/181 [00:09<00:48,  3.11it/s]\u001b[A\n",
      " 17%|█▋        | 30/181 [00:09<00:48,  3.11it/s]\u001b[A\n",
      " 17%|█▋        | 31/181 [00:09<00:48,  3.11it/s]\u001b[A\n",
      " 18%|█▊        | 32/181 [00:10<00:48,  3.10it/s]\u001b[A\n",
      " 18%|█▊        | 33/181 [00:10<00:47,  3.10it/s]\u001b[A\n",
      " 19%|█▉        | 34/181 [00:10<00:47,  3.11it/s]\u001b[A\n",
      " 19%|█▉        | 35/181 [00:11<00:46,  3.11it/s]\u001b[A\n",
      " 20%|█▉        | 36/181 [00:11<00:46,  3.10it/s]\u001b[A\n",
      " 20%|██        | 37/181 [00:11<00:46,  3.10it/s]\u001b[A\n",
      " 21%|██        | 38/181 [00:12<00:46,  3.10it/s]\u001b[A\n",
      " 22%|██▏       | 39/181 [00:12<00:45,  3.10it/s]\u001b[A\n",
      " 22%|██▏       | 40/181 [00:12<00:45,  3.11it/s]\u001b[A\n",
      " 23%|██▎       | 41/181 [00:13<00:45,  3.11it/s]\u001b[A\n",
      " 23%|██▎       | 42/181 [00:13<00:44,  3.10it/s]\u001b[A\n",
      " 24%|██▍       | 43/181 [00:13<00:44,  3.10it/s]\u001b[A\n",
      " 24%|██▍       | 44/181 [00:14<00:44,  3.10it/s]\u001b[A\n",
      " 25%|██▍       | 45/181 [00:14<00:43,  3.11it/s]\u001b[A\n",
      " 25%|██▌       | 46/181 [00:14<00:43,  3.11it/s]\u001b[A\n",
      " 26%|██▌       | 47/181 [00:15<00:43,  3.11it/s]\u001b[A\n",
      " 27%|██▋       | 48/181 [00:15<00:42,  3.11it/s]\u001b[A\n",
      " 27%|██▋       | 49/181 [00:15<00:42,  3.10it/s]\u001b[A\n",
      " 28%|██▊       | 50/181 [00:16<00:42,  3.10it/s]\u001b[A\n",
      " 28%|██▊       | 51/181 [00:16<00:41,  3.10it/s]\u001b[A\n",
      " 29%|██▊       | 52/181 [00:16<00:41,  3.10it/s]\u001b[A\n",
      " 29%|██▉       | 53/181 [00:17<00:41,  3.11it/s]\u001b[A\n",
      " 30%|██▉       | 54/181 [00:17<00:40,  3.11it/s]\u001b[A\n",
      " 30%|███       | 55/181 [00:17<00:40,  3.11it/s]\u001b[A\n",
      " 31%|███       | 56/181 [00:18<00:40,  3.11it/s]\u001b[A\n",
      " 31%|███▏      | 57/181 [00:18<00:39,  3.11it/s]\u001b[A\n",
      " 32%|███▏      | 58/181 [00:18<00:39,  3.10it/s]\u001b[A\n",
      " 33%|███▎      | 59/181 [00:19<00:39,  3.11it/s]\u001b[A\n",
      " 33%|███▎      | 60/181 [00:19<00:38,  3.10it/s]\u001b[A\n",
      " 34%|███▎      | 61/181 [00:19<00:38,  3.10it/s]\u001b[A\n",
      " 34%|███▍      | 62/181 [00:19<00:38,  3.10it/s]\u001b[A\n",
      " 35%|███▍      | 63/181 [00:20<00:38,  3.10it/s]\u001b[A\n",
      " 35%|███▌      | 64/181 [00:20<00:37,  3.10it/s]\u001b[A\n",
      " 36%|███▌      | 65/181 [00:20<00:37,  3.10it/s]\u001b[A\n",
      " 36%|███▋      | 66/181 [00:21<00:37,  3.10it/s]\u001b[A\n",
      " 37%|███▋      | 67/181 [00:21<00:36,  3.10it/s]\u001b[A\n",
      " 38%|███▊      | 68/181 [00:21<00:36,  3.10it/s]\u001b[A\n",
      " 38%|███▊      | 69/181 [00:22<00:36,  3.10it/s]\u001b[A\n",
      " 39%|███▊      | 70/181 [00:22<00:35,  3.10it/s]\u001b[A\n",
      " 39%|███▉      | 71/181 [00:22<00:35,  3.10it/s]\u001b[A\n",
      " 40%|███▉      | 72/181 [00:23<00:35,  3.10it/s]\u001b[A\n",
      " 40%|████      | 73/181 [00:23<00:34,  3.10it/s]\u001b[A\n",
      " 41%|████      | 74/181 [00:23<00:34,  3.10it/s]\u001b[A\n",
      " 41%|████▏     | 75/181 [00:24<00:34,  3.10it/s]\u001b[A\n",
      " 42%|████▏     | 76/181 [00:24<00:33,  3.10it/s]\u001b[A\n",
      " 43%|████▎     | 77/181 [00:24<00:33,  3.09it/s]\u001b[A\n",
      " 43%|████▎     | 78/181 [00:25<00:33,  3.09it/s]\u001b[A\n",
      " 44%|████▎     | 79/181 [00:25<00:32,  3.10it/s]\u001b[A\n",
      " 44%|████▍     | 80/181 [00:25<00:32,  3.10it/s]\u001b[A\n",
      " 45%|████▍     | 81/181 [00:26<00:32,  3.10it/s]\u001b[A\n",
      " 45%|████▌     | 82/181 [00:26<00:31,  3.10it/s]\u001b[A\n",
      " 46%|████▌     | 83/181 [00:26<00:31,  3.10it/s]\u001b[A\n",
      " 46%|████▋     | 84/181 [00:27<00:31,  3.10it/s]\u001b[A\n",
      " 47%|████▋     | 85/181 [00:27<00:31,  3.10it/s]\u001b[A\n",
      " 48%|████▊     | 86/181 [00:27<00:30,  3.10it/s]\u001b[A\n",
      " 48%|████▊     | 87/181 [00:28<00:30,  3.10it/s]\u001b[A\n",
      " 49%|████▊     | 88/181 [00:28<00:30,  3.09it/s]\u001b[A\n",
      " 49%|████▉     | 89/181 [00:28<00:29,  3.10it/s]\u001b[A\n",
      " 50%|████▉     | 90/181 [00:29<00:29,  3.10it/s]\u001b[A\n",
      " 50%|█████     | 91/181 [00:29<00:29,  3.10it/s]\u001b[A\n",
      " 51%|█████     | 92/181 [00:29<00:28,  3.10it/s]\u001b[A\n",
      " 51%|█████▏    | 93/181 [00:29<00:28,  3.10it/s]\u001b[A\n",
      " 52%|█████▏    | 94/181 [00:30<00:28,  3.10it/s]\u001b[A\n",
      " 52%|█████▏    | 95/181 [00:30<00:27,  3.10it/s]\u001b[A\n",
      " 53%|█████▎    | 96/181 [00:30<00:27,  3.10it/s]\u001b[A\n",
      " 54%|█████▎    | 97/181 [00:31<00:27,  3.10it/s]\u001b[A\n",
      " 54%|█████▍    | 98/181 [00:31<00:26,  3.10it/s]\u001b[A\n",
      " 55%|█████▍    | 99/181 [00:31<00:26,  3.10it/s]\u001b[A\n",
      " 55%|█████▌    | 100/181 [00:32<00:26,  3.10it/s]\u001b[A\n",
      " 56%|█████▌    | 101/181 [00:32<00:25,  3.10it/s]\u001b[A\n",
      " 56%|█████▋    | 102/181 [00:32<00:25,  3.10it/s]\u001b[A\n",
      " 57%|█████▋    | 103/181 [00:33<00:25,  3.10it/s]\u001b[A\n",
      " 57%|█████▋    | 104/181 [00:33<00:24,  3.10it/s]\u001b[A\n",
      " 58%|█████▊    | 105/181 [00:33<00:24,  3.10it/s]\u001b[A\n",
      " 59%|█████▊    | 106/181 [00:34<00:24,  3.10it/s]\u001b[A\n",
      " 59%|█████▉    | 107/181 [00:34<00:23,  3.10it/s]\u001b[A\n",
      " 60%|█████▉    | 108/181 [00:34<00:23,  3.10it/s]\u001b[A\n",
      " 60%|██████    | 109/181 [00:35<00:23,  3.10it/s]\u001b[A\n",
      " 61%|██████    | 110/181 [00:35<00:22,  3.10it/s]\u001b[A\n",
      " 61%|██████▏   | 111/181 [00:35<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 112/181 [00:36<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 113/181 [00:36<00:21,  3.10it/s]\u001b[A\n",
      " 63%|██████▎   | 114/181 [00:36<00:21,  3.10it/s]\u001b[A\n",
      " 64%|██████▎   | 115/181 [00:37<00:21,  3.11it/s]\u001b[A\n",
      " 64%|██████▍   | 116/181 [00:37<00:20,  3.11it/s]\u001b[A\n",
      " 65%|██████▍   | 117/181 [00:37<00:20,  3.11it/s]\u001b[A\n",
      " 65%|██████▌   | 118/181 [00:38<00:20,  3.11it/s]\u001b[A\n",
      " 66%|██████▌   | 119/181 [00:38<00:19,  3.11it/s]\u001b[A\n",
      " 66%|██████▋   | 120/181 [00:38<00:19,  3.11it/s]\u001b[A\n",
      " 67%|██████▋   | 121/181 [00:39<00:19,  3.11it/s]\u001b[A\n",
      " 67%|██████▋   | 122/181 [00:39<00:19,  3.10it/s]\u001b[A\n",
      " 68%|██████▊   | 123/181 [00:39<00:18,  3.11it/s]\u001b[A\n",
      " 69%|██████▊   | 124/181 [00:39<00:18,  3.11it/s]\u001b[A\n",
      " 69%|██████▉   | 125/181 [00:40<00:18,  3.11it/s]\u001b[A\n",
      " 70%|██████▉   | 126/181 [00:40<00:17,  3.11it/s]\u001b[A\n",
      " 70%|███████   | 127/181 [00:40<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████   | 128/181 [00:41<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████▏  | 129/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 130/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 131/181 [00:42<00:16,  3.10it/s]\u001b[A\n",
      " 73%|███████▎  | 132/181 [00:42<00:15,  3.10it/s]\u001b[A\n",
      " 73%|███████▎  | 133/181 [00:42<00:15,  3.10it/s]\u001b[A\n",
      " 74%|███████▍  | 134/181 [00:43<00:15,  3.10it/s]\u001b[A\n",
      " 75%|███████▍  | 135/181 [00:43<00:14,  3.11it/s]\u001b[A\n",
      " 75%|███████▌  | 136/181 [00:43<00:14,  3.11it/s]\u001b[A\n",
      " 76%|███████▌  | 137/181 [00:44<00:14,  3.11it/s]\u001b[A\n",
      " 76%|███████▌  | 138/181 [00:44<00:13,  3.11it/s]\u001b[A\n",
      " 77%|███████▋  | 139/181 [00:44<00:13,  3.11it/s]\u001b[A\n",
      " 77%|███████▋  | 140/181 [00:45<00:13,  3.11it/s]\u001b[A\n",
      " 78%|███████▊  | 141/181 [00:45<00:12,  3.11it/s]\u001b[A\n",
      " 78%|███████▊  | 142/181 [00:45<00:12,  3.11it/s]\u001b[A\n",
      " 79%|███████▉  | 143/181 [00:46<00:12,  3.10it/s]\u001b[A\n",
      " 80%|███████▉  | 144/181 [00:46<00:11,  3.09it/s]\u001b[A\n",
      " 80%|████████  | 145/181 [00:46<00:11,  3.10it/s]\u001b[A\n",
      " 81%|████████  | 146/181 [00:47<00:11,  3.10it/s]\u001b[A\n",
      " 81%|████████  | 147/181 [00:47<00:10,  3.10it/s]\u001b[A\n",
      " 82%|████████▏ | 148/181 [00:47<00:10,  3.11it/s]\u001b[A\n",
      " 82%|████████▏ | 149/181 [00:48<00:10,  3.11it/s]\u001b[A\n",
      " 83%|████████▎ | 150/181 [00:48<00:09,  3.11it/s]\u001b[A\n",
      " 83%|████████▎ | 151/181 [00:48<00:09,  3.11it/s]\u001b[A\n",
      " 84%|████████▍ | 152/181 [00:48<00:09,  3.11it/s]\u001b[A\n",
      " 85%|████████▍ | 153/181 [00:49<00:09,  3.11it/s]\u001b[A\n",
      " 85%|████████▌ | 154/181 [00:49<00:08,  3.11it/s]\u001b[A\n",
      " 86%|████████▌ | 155/181 [00:49<00:08,  3.11it/s]\u001b[A\n",
      " 86%|████████▌ | 156/181 [00:50<00:08,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 157/181 [00:50<00:07,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 158/181 [00:50<00:07,  3.11it/s]\u001b[A\n",
      " 88%|████████▊ | 159/181 [00:51<00:07,  3.11it/s]\u001b[A\n",
      " 88%|████████▊ | 160/181 [00:51<00:06,  3.11it/s]\u001b[A\n",
      " 89%|████████▉ | 161/181 [00:51<00:06,  3.11it/s]\u001b[A\n",
      " 90%|████████▉ | 162/181 [00:52<00:06,  3.10it/s]\u001b[A\n",
      " 90%|█████████ | 163/181 [00:52<00:05,  3.10it/s]\u001b[A\n",
      " 91%|█████████ | 164/181 [00:52<00:05,  3.11it/s]\u001b[A\n",
      " 91%|█████████ | 165/181 [00:53<00:05,  3.10it/s]\u001b[A\n",
      " 92%|█████████▏| 166/181 [00:53<00:04,  3.09it/s]\u001b[A\n",
      " 92%|█████████▏| 167/181 [00:53<00:04,  3.09it/s]\u001b[A\n",
      " 93%|█████████▎| 168/181 [00:54<00:04,  3.10it/s]\u001b[A\n",
      " 93%|█████████▎| 169/181 [00:54<00:03,  3.10it/s]\u001b[A\n",
      " 94%|█████████▍| 170/181 [00:54<00:03,  3.11it/s]\u001b[A\n",
      " 94%|█████████▍| 171/181 [00:55<00:03,  3.10it/s]\u001b[A\n",
      " 95%|█████████▌| 172/181 [00:55<00:02,  3.10it/s]\u001b[A\n",
      " 96%|█████████▌| 173/181 [00:55<00:02,  3.11it/s]\u001b[A\n",
      " 96%|█████████▌| 174/181 [00:56<00:02,  3.11it/s]\u001b[A\n",
      " 97%|█████████▋| 175/181 [00:56<00:01,  3.10it/s]\u001b[A\n",
      " 97%|█████████▋| 176/181 [00:56<00:01,  3.10it/s]\u001b[A\n",
      " 98%|█████████▊| 177/181 [00:57<00:01,  3.10it/s]\u001b[A\n",
      " 98%|█████████▊| 178/181 [00:57<00:00,  3.10it/s]\u001b[A\n",
      " 99%|█████████▉| 179/181 [00:57<00:00,  3.10it/s]\u001b[A\n",
      " 99%|█████████▉| 180/181 [00:58<00:00,  3.10it/s]\u001b[A\n",
      "100%|██████████| 181/181 [00:58<00:00,  3.11it/s]\u001b[A\n",
      "Epoch:  50%|█████     | 2/4 [18:54<18:53, 566.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.54\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  1,494.    Elapsed: 0:02:51.\n",
      "  Batch 1,000  of  1,494.    Elapsed: 0:05:42.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/181 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:08:31\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/181 [00:00<00:57,  3.13it/s]\u001b[A\n",
      "  1%|          | 2/181 [00:00<00:57,  3.12it/s]\u001b[A\n",
      "  2%|▏         | 3/181 [00:00<00:57,  3.11it/s]\u001b[A\n",
      "  2%|▏         | 4/181 [00:01<00:56,  3.11it/s]\u001b[A\n",
      "  3%|▎         | 5/181 [00:01<00:56,  3.10it/s]\u001b[A\n",
      "  3%|▎         | 6/181 [00:01<00:56,  3.10it/s]\u001b[A\n",
      "  4%|▍         | 7/181 [00:02<00:56,  3.11it/s]\u001b[A\n",
      "  4%|▍         | 8/181 [00:02<00:55,  3.10it/s]\u001b[A\n",
      "  5%|▍         | 9/181 [00:02<00:55,  3.10it/s]\u001b[A\n",
      "  6%|▌         | 10/181 [00:03<00:55,  3.10it/s]\u001b[A\n",
      "  6%|▌         | 11/181 [00:03<00:54,  3.10it/s]\u001b[A\n",
      "  7%|▋         | 12/181 [00:03<00:54,  3.10it/s]\u001b[A\n",
      "  7%|▋         | 13/181 [00:04<00:54,  3.10it/s]\u001b[A\n",
      "  8%|▊         | 14/181 [00:04<00:53,  3.10it/s]\u001b[A\n",
      "  8%|▊         | 15/181 [00:04<00:53,  3.10it/s]\u001b[A\n",
      "  9%|▉         | 16/181 [00:05<00:53,  3.10it/s]\u001b[A\n",
      "  9%|▉         | 17/181 [00:05<00:52,  3.10it/s]\u001b[A\n",
      " 10%|▉         | 18/181 [00:05<00:52,  3.10it/s]\u001b[A\n",
      " 10%|█         | 19/181 [00:06<00:52,  3.10it/s]\u001b[A\n",
      " 11%|█         | 20/181 [00:06<00:51,  3.11it/s]\u001b[A\n",
      " 12%|█▏        | 21/181 [00:06<00:51,  3.11it/s]\u001b[A\n",
      " 12%|█▏        | 22/181 [00:07<00:51,  3.11it/s]\u001b[A\n",
      " 13%|█▎        | 23/181 [00:07<00:50,  3.11it/s]\u001b[A\n",
      " 13%|█▎        | 24/181 [00:07<00:50,  3.11it/s]\u001b[A\n",
      " 14%|█▍        | 25/181 [00:08<00:50,  3.11it/s]\u001b[A\n",
      " 14%|█▍        | 26/181 [00:08<00:49,  3.11it/s]\u001b[A\n",
      " 15%|█▍        | 27/181 [00:08<00:49,  3.10it/s]\u001b[A\n",
      " 15%|█▌        | 28/181 [00:09<00:49,  3.10it/s]\u001b[A\n",
      " 16%|█▌        | 29/181 [00:09<00:49,  3.10it/s]\u001b[A\n",
      " 17%|█▋        | 30/181 [00:09<00:48,  3.10it/s]\u001b[A\n",
      " 17%|█▋        | 31/181 [00:09<00:48,  3.10it/s]\u001b[A\n",
      " 18%|█▊        | 32/181 [00:10<00:48,  3.10it/s]\u001b[A\n",
      " 18%|█▊        | 33/181 [00:10<00:47,  3.10it/s]\u001b[A\n",
      " 19%|█▉        | 34/181 [00:10<00:47,  3.11it/s]\u001b[A\n",
      " 19%|█▉        | 35/181 [00:11<00:46,  3.11it/s]\u001b[A\n",
      " 20%|█▉        | 36/181 [00:11<00:46,  3.11it/s]\u001b[A\n",
      " 20%|██        | 37/181 [00:11<00:46,  3.11it/s]\u001b[A\n",
      " 21%|██        | 38/181 [00:12<00:46,  3.11it/s]\u001b[A\n",
      " 22%|██▏       | 39/181 [00:12<00:45,  3.10it/s]\u001b[A\n",
      " 22%|██▏       | 40/181 [00:12<00:45,  3.10it/s]\u001b[A\n",
      " 23%|██▎       | 41/181 [00:13<00:45,  3.11it/s]\u001b[A\n",
      " 23%|██▎       | 42/181 [00:13<00:44,  3.11it/s]\u001b[A\n",
      " 24%|██▍       | 43/181 [00:13<00:44,  3.11it/s]\u001b[A\n",
      " 24%|██▍       | 44/181 [00:14<00:44,  3.10it/s]\u001b[A\n",
      " 25%|██▍       | 45/181 [00:14<00:43,  3.10it/s]\u001b[A\n",
      " 25%|██▌       | 46/181 [00:14<00:43,  3.10it/s]\u001b[A\n",
      " 26%|██▌       | 47/181 [00:15<00:43,  3.11it/s]\u001b[A\n",
      " 27%|██▋       | 48/181 [00:15<00:42,  3.11it/s]\u001b[A\n",
      " 27%|██▋       | 49/181 [00:15<00:42,  3.11it/s]\u001b[A\n",
      " 28%|██▊       | 50/181 [00:16<00:42,  3.11it/s]\u001b[A\n",
      " 28%|██▊       | 51/181 [00:16<00:41,  3.11it/s]\u001b[A\n",
      " 29%|██▊       | 52/181 [00:16<00:41,  3.11it/s]\u001b[A\n",
      " 29%|██▉       | 53/181 [00:17<00:41,  3.11it/s]\u001b[A\n",
      " 30%|██▉       | 54/181 [00:17<00:40,  3.10it/s]\u001b[A\n",
      " 30%|███       | 55/181 [00:17<00:40,  3.10it/s]\u001b[A\n",
      " 31%|███       | 56/181 [00:18<00:40,  3.10it/s]\u001b[A\n",
      " 31%|███▏      | 57/181 [00:18<00:40,  3.10it/s]\u001b[A\n",
      " 32%|███▏      | 58/181 [00:18<00:39,  3.10it/s]\u001b[A\n",
      " 33%|███▎      | 59/181 [00:19<00:39,  3.10it/s]\u001b[A\n",
      " 33%|███▎      | 60/181 [00:19<00:38,  3.10it/s]\u001b[A\n",
      " 34%|███▎      | 61/181 [00:19<00:38,  3.11it/s]\u001b[A\n",
      " 34%|███▍      | 62/181 [00:19<00:38,  3.10it/s]\u001b[A\n",
      " 35%|███▍      | 63/181 [00:20<00:37,  3.11it/s]\u001b[A\n",
      " 35%|███▌      | 64/181 [00:20<00:37,  3.11it/s]\u001b[A\n",
      " 36%|███▌      | 65/181 [00:20<00:37,  3.10it/s]\u001b[A\n",
      " 36%|███▋      | 66/181 [00:21<00:37,  3.10it/s]\u001b[A\n",
      " 37%|███▋      | 67/181 [00:21<00:36,  3.10it/s]\u001b[A\n",
      " 38%|███▊      | 68/181 [00:21<00:36,  3.10it/s]\u001b[A\n",
      " 38%|███▊      | 69/181 [00:22<00:36,  3.10it/s]\u001b[A\n",
      " 39%|███▊      | 70/181 [00:22<00:35,  3.11it/s]\u001b[A\n",
      " 39%|███▉      | 71/181 [00:22<00:35,  3.11it/s]\u001b[A\n",
      " 40%|███▉      | 72/181 [00:23<00:35,  3.10it/s]\u001b[A\n",
      " 40%|████      | 73/181 [00:23<00:34,  3.10it/s]\u001b[A\n",
      " 41%|████      | 74/181 [00:23<00:34,  3.10it/s]\u001b[A\n",
      " 41%|████▏     | 75/181 [00:24<00:34,  3.10it/s]\u001b[A\n",
      " 42%|████▏     | 76/181 [00:24<00:33,  3.10it/s]\u001b[A\n",
      " 43%|████▎     | 77/181 [00:24<00:33,  3.10it/s]\u001b[A\n",
      " 43%|████▎     | 78/181 [00:25<00:33,  3.10it/s]\u001b[A\n",
      " 44%|████▎     | 79/181 [00:25<00:32,  3.10it/s]\u001b[A\n",
      " 44%|████▍     | 80/181 [00:25<00:32,  3.10it/s]\u001b[A\n",
      " 45%|████▍     | 81/181 [00:26<00:32,  3.10it/s]\u001b[A\n",
      " 45%|████▌     | 82/181 [00:26<00:31,  3.10it/s]\u001b[A\n",
      " 46%|████▌     | 83/181 [00:26<00:31,  3.10it/s]\u001b[A\n",
      " 46%|████▋     | 84/181 [00:27<00:31,  3.10it/s]\u001b[A\n",
      " 47%|████▋     | 85/181 [00:27<00:31,  3.10it/s]\u001b[A\n",
      " 48%|████▊     | 86/181 [00:27<00:30,  3.09it/s]\u001b[A\n",
      " 48%|████▊     | 87/181 [00:28<00:30,  3.10it/s]\u001b[A\n",
      " 49%|████▊     | 88/181 [00:28<00:30,  3.10it/s]\u001b[A\n",
      " 49%|████▉     | 89/181 [00:28<00:29,  3.10it/s]\u001b[A\n",
      " 50%|████▉     | 90/181 [00:29<00:29,  3.09it/s]\u001b[A\n",
      " 50%|█████     | 91/181 [00:29<00:29,  3.10it/s]\u001b[A\n",
      " 51%|█████     | 92/181 [00:29<00:28,  3.10it/s]\u001b[A\n",
      " 51%|█████▏    | 93/181 [00:29<00:28,  3.10it/s]\u001b[A\n",
      " 52%|█████▏    | 94/181 [00:30<00:28,  3.10it/s]\u001b[A\n",
      " 52%|█████▏    | 95/181 [00:30<00:27,  3.11it/s]\u001b[A\n",
      " 53%|█████▎    | 96/181 [00:30<00:27,  3.11it/s]\u001b[A\n",
      " 54%|█████▎    | 97/181 [00:31<00:27,  3.10it/s]\u001b[A\n",
      " 54%|█████▍    | 98/181 [00:31<00:26,  3.10it/s]\u001b[A\n",
      " 55%|█████▍    | 99/181 [00:31<00:26,  3.10it/s]\u001b[A\n",
      " 55%|█████▌    | 100/181 [00:32<00:26,  3.10it/s]\u001b[A\n",
      " 56%|█████▌    | 101/181 [00:32<00:25,  3.10it/s]\u001b[A\n",
      " 56%|█████▋    | 102/181 [00:32<00:25,  3.09it/s]\u001b[A\n",
      " 57%|█████▋    | 103/181 [00:33<00:25,  3.10it/s]\u001b[A\n",
      " 57%|█████▋    | 104/181 [00:33<00:24,  3.10it/s]\u001b[A\n",
      " 58%|█████▊    | 105/181 [00:33<00:24,  3.10it/s]\u001b[A\n",
      " 59%|█████▊    | 106/181 [00:34<00:24,  3.10it/s]\u001b[A\n",
      " 59%|█████▉    | 107/181 [00:34<00:23,  3.10it/s]\u001b[A\n",
      " 60%|█████▉    | 108/181 [00:34<00:23,  3.11it/s]\u001b[A\n",
      " 60%|██████    | 109/181 [00:35<00:23,  3.11it/s]\u001b[A\n",
      " 61%|██████    | 110/181 [00:35<00:22,  3.11it/s]\u001b[A\n",
      " 61%|██████▏   | 111/181 [00:35<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 112/181 [00:36<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 113/181 [00:36<00:21,  3.11it/s]\u001b[A\n",
      " 63%|██████▎   | 114/181 [00:36<00:21,  3.11it/s]\u001b[A\n",
      " 64%|██████▎   | 115/181 [00:37<00:21,  3.11it/s]\u001b[A\n",
      " 64%|██████▍   | 116/181 [00:37<00:20,  3.10it/s]\u001b[A\n",
      " 65%|██████▍   | 117/181 [00:37<00:20,  3.10it/s]\u001b[A\n",
      " 65%|██████▌   | 118/181 [00:38<00:20,  3.10it/s]\u001b[A\n",
      " 66%|██████▌   | 119/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 66%|██████▋   | 120/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 67%|██████▋   | 121/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 67%|██████▋   | 122/181 [00:39<00:19,  3.10it/s]\u001b[A\n",
      " 68%|██████▊   | 123/181 [00:39<00:18,  3.10it/s]\u001b[A\n",
      " 69%|██████▊   | 124/181 [00:39<00:18,  3.10it/s]\u001b[A\n",
      " 69%|██████▉   | 125/181 [00:40<00:18,  3.10it/s]\u001b[A\n",
      " 70%|██████▉   | 126/181 [00:40<00:17,  3.10it/s]\u001b[A\n",
      " 70%|███████   | 127/181 [00:40<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████   | 128/181 [00:41<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████▏  | 129/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 130/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 131/181 [00:42<00:16,  3.10it/s]\u001b[A\n",
      " 73%|███████▎  | 132/181 [00:42<00:15,  3.10it/s]\u001b[A\n",
      " 73%|███████▎  | 133/181 [00:42<00:15,  3.10it/s]\u001b[A\n",
      " 74%|███████▍  | 134/181 [00:43<00:15,  3.10it/s]\u001b[A\n",
      " 75%|███████▍  | 135/181 [00:43<00:14,  3.09it/s]\u001b[A\n",
      " 75%|███████▌  | 136/181 [00:43<00:14,  3.09it/s]\u001b[A\n",
      " 76%|███████▌  | 137/181 [00:44<00:14,  3.09it/s]\u001b[A\n",
      " 76%|███████▌  | 138/181 [00:44<00:13,  3.09it/s]\u001b[A\n",
      " 77%|███████▋  | 139/181 [00:44<00:13,  3.10it/s]\u001b[A\n",
      " 77%|███████▋  | 140/181 [00:45<00:13,  3.10it/s]\u001b[A\n",
      " 78%|███████▊  | 141/181 [00:45<00:12,  3.10it/s]\u001b[A\n",
      " 78%|███████▊  | 142/181 [00:45<00:12,  3.09it/s]\u001b[A\n",
      " 79%|███████▉  | 143/181 [00:46<00:12,  3.09it/s]\u001b[A\n",
      " 80%|███████▉  | 144/181 [00:46<00:11,  3.10it/s]\u001b[A\n",
      " 80%|████████  | 145/181 [00:46<00:11,  3.10it/s]\u001b[A\n",
      " 81%|████████  | 146/181 [00:47<00:11,  3.09it/s]\u001b[A\n",
      " 81%|████████  | 147/181 [00:47<00:10,  3.09it/s]\u001b[A\n",
      " 82%|████████▏ | 148/181 [00:47<00:10,  3.09it/s]\u001b[A\n",
      " 82%|████████▏ | 149/181 [00:48<00:10,  3.10it/s]\u001b[A\n",
      " 83%|████████▎ | 150/181 [00:48<00:10,  3.10it/s]\u001b[A\n",
      " 83%|████████▎ | 151/181 [00:48<00:09,  3.10it/s]\u001b[A\n",
      " 84%|████████▍ | 152/181 [00:49<00:09,  3.10it/s]\u001b[A\n",
      " 85%|████████▍ | 153/181 [00:49<00:09,  3.10it/s]\u001b[A\n",
      " 85%|████████▌ | 154/181 [00:49<00:08,  3.10it/s]\u001b[A\n",
      " 86%|████████▌ | 155/181 [00:49<00:08,  3.10it/s]\u001b[A\n",
      " 86%|████████▌ | 156/181 [00:50<00:08,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 157/181 [00:50<00:07,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 158/181 [00:50<00:07,  3.10it/s]\u001b[A\n",
      " 88%|████████▊ | 159/181 [00:51<00:07,  3.10it/s]\u001b[A\n",
      " 88%|████████▊ | 160/181 [00:51<00:06,  3.10it/s]\u001b[A\n",
      " 89%|████████▉ | 161/181 [00:51<00:06,  3.10it/s]\u001b[A\n",
      " 90%|████████▉ | 162/181 [00:52<00:06,  3.09it/s]\u001b[A\n",
      " 90%|█████████ | 163/181 [00:52<00:05,  3.10it/s]\u001b[A\n",
      " 91%|█████████ | 164/181 [00:52<00:05,  3.10it/s]\u001b[A\n",
      " 91%|█████████ | 165/181 [00:53<00:05,  3.10it/s]\u001b[A\n",
      " 92%|█████████▏| 166/181 [00:53<00:04,  3.10it/s]\u001b[A\n",
      " 92%|█████████▏| 167/181 [00:53<00:04,  3.11it/s]\u001b[A\n",
      " 93%|█████████▎| 168/181 [00:54<00:04,  3.11it/s]\u001b[A\n",
      " 93%|█████████▎| 169/181 [00:54<00:03,  3.11it/s]\u001b[A\n",
      " 94%|█████████▍| 170/181 [00:54<00:03,  3.10it/s]\u001b[A\n",
      " 94%|█████████▍| 171/181 [00:55<00:03,  3.10it/s]\u001b[A\n",
      " 95%|█████████▌| 172/181 [00:55<00:02,  3.10it/s]\u001b[A\n",
      " 96%|█████████▌| 173/181 [00:55<00:02,  3.10it/s]\u001b[A\n",
      " 96%|█████████▌| 174/181 [00:56<00:02,  3.10it/s]\u001b[A\n",
      " 97%|█████████▋| 175/181 [00:56<00:01,  3.10it/s]\u001b[A\n",
      " 97%|█████████▋| 176/181 [00:56<00:01,  3.10it/s]\u001b[A\n",
      " 98%|█████████▊| 177/181 [00:57<00:01,  3.10it/s]\u001b[A\n",
      " 98%|█████████▊| 178/181 [00:57<00:00,  3.11it/s]\u001b[A\n",
      " 99%|█████████▉| 179/181 [00:57<00:00,  3.11it/s]\u001b[A\n",
      " 99%|█████████▉| 180/181 [00:58<00:00,  3.11it/s]\u001b[A\n",
      "100%|██████████| 181/181 [00:58<00:00,  3.11it/s]\u001b[A\n",
      "Epoch:  75%|███████▌  | 3/4 [28:23<09:27, 567.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.54\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  1,494.    Elapsed: 0:02:51.\n",
      "  Batch 1,000  of  1,494.    Elapsed: 0:05:42.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/181 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:08:30\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/181 [00:00<00:57,  3.13it/s]\u001b[A\n",
      "  1%|          | 2/181 [00:00<00:57,  3.13it/s]\u001b[A\n",
      "  2%|▏         | 3/181 [00:00<00:57,  3.12it/s]\u001b[A\n",
      "  2%|▏         | 4/181 [00:01<00:56,  3.12it/s]\u001b[A\n",
      "  3%|▎         | 5/181 [00:01<00:56,  3.11it/s]\u001b[A\n",
      "  3%|▎         | 6/181 [00:01<00:56,  3.11it/s]\u001b[A\n",
      "  4%|▍         | 7/181 [00:02<00:56,  3.11it/s]\u001b[A\n",
      "  4%|▍         | 8/181 [00:02<00:55,  3.10it/s]\u001b[A\n",
      "  5%|▍         | 9/181 [00:02<00:55,  3.10it/s]\u001b[A\n",
      "  6%|▌         | 10/181 [00:03<00:55,  3.11it/s]\u001b[A\n",
      "  6%|▌         | 11/181 [00:03<00:54,  3.11it/s]\u001b[A\n",
      "  7%|▋         | 12/181 [00:03<00:54,  3.11it/s]\u001b[A\n",
      "  7%|▋         | 13/181 [00:04<00:54,  3.11it/s]\u001b[A\n",
      "  8%|▊         | 14/181 [00:04<00:53,  3.11it/s]\u001b[A\n",
      "  8%|▊         | 15/181 [00:04<00:53,  3.11it/s]\u001b[A\n",
      "  9%|▉         | 16/181 [00:05<00:53,  3.11it/s]\u001b[A\n",
      "  9%|▉         | 17/181 [00:05<00:52,  3.11it/s]\u001b[A\n",
      " 10%|▉         | 18/181 [00:05<00:52,  3.11it/s]\u001b[A\n",
      " 10%|█         | 19/181 [00:06<00:52,  3.11it/s]\u001b[A\n",
      " 11%|█         | 20/181 [00:06<00:51,  3.11it/s]\u001b[A\n",
      " 12%|█▏        | 21/181 [00:06<00:51,  3.11it/s]\u001b[A\n",
      " 12%|█▏        | 22/181 [00:07<00:51,  3.11it/s]\u001b[A\n",
      " 13%|█▎        | 23/181 [00:07<00:50,  3.11it/s]\u001b[A\n",
      " 13%|█▎        | 24/181 [00:07<00:50,  3.11it/s]\u001b[A\n",
      " 14%|█▍        | 25/181 [00:08<00:50,  3.11it/s]\u001b[A\n",
      " 14%|█▍        | 26/181 [00:08<00:49,  3.11it/s]\u001b[A\n",
      " 15%|█▍        | 27/181 [00:08<00:49,  3.11it/s]\u001b[A\n",
      " 15%|█▌        | 28/181 [00:09<00:49,  3.11it/s]\u001b[A\n",
      " 16%|█▌        | 29/181 [00:09<00:48,  3.11it/s]\u001b[A\n",
      " 17%|█▋        | 30/181 [00:09<00:48,  3.11it/s]\u001b[A\n",
      " 17%|█▋        | 31/181 [00:09<00:48,  3.11it/s]\u001b[A\n",
      " 18%|█▊        | 32/181 [00:10<00:47,  3.11it/s]\u001b[A\n",
      " 18%|█▊        | 33/181 [00:10<00:47,  3.11it/s]\u001b[A\n",
      " 19%|█▉        | 34/181 [00:10<00:47,  3.11it/s]\u001b[A\n",
      " 19%|█▉        | 35/181 [00:11<00:47,  3.10it/s]\u001b[A\n",
      " 20%|█▉        | 36/181 [00:11<00:46,  3.10it/s]\u001b[A\n",
      " 20%|██        | 37/181 [00:11<00:46,  3.10it/s]\u001b[A\n",
      " 21%|██        | 38/181 [00:12<00:46,  3.11it/s]\u001b[A\n",
      " 22%|██▏       | 39/181 [00:12<00:45,  3.10it/s]\u001b[A\n",
      " 22%|██▏       | 40/181 [00:12<00:45,  3.10it/s]\u001b[A\n",
      " 23%|██▎       | 41/181 [00:13<00:45,  3.10it/s]\u001b[A\n",
      " 23%|██▎       | 42/181 [00:13<00:44,  3.10it/s]\u001b[A\n",
      " 24%|██▍       | 43/181 [00:13<00:44,  3.10it/s]\u001b[A\n",
      " 24%|██▍       | 44/181 [00:14<00:44,  3.10it/s]\u001b[A\n",
      " 25%|██▍       | 45/181 [00:14<00:43,  3.10it/s]\u001b[A\n",
      " 25%|██▌       | 46/181 [00:14<00:43,  3.10it/s]\u001b[A\n",
      " 26%|██▌       | 47/181 [00:15<00:43,  3.10it/s]\u001b[A\n",
      " 27%|██▋       | 48/181 [00:15<00:42,  3.10it/s]\u001b[A\n",
      " 27%|██▋       | 49/181 [00:15<00:42,  3.10it/s]\u001b[A\n",
      " 28%|██▊       | 50/181 [00:16<00:42,  3.10it/s]\u001b[A\n",
      " 28%|██▊       | 51/181 [00:16<00:41,  3.10it/s]\u001b[A\n",
      " 29%|██▊       | 52/181 [00:16<00:41,  3.10it/s]\u001b[A\n",
      " 29%|██▉       | 53/181 [00:17<00:41,  3.10it/s]\u001b[A\n",
      " 30%|██▉       | 54/181 [00:17<00:40,  3.11it/s]\u001b[A\n",
      " 30%|███       | 55/181 [00:17<00:40,  3.10it/s]\u001b[A\n",
      " 31%|███       | 56/181 [00:18<00:40,  3.09it/s]\u001b[A\n",
      " 31%|███▏      | 57/181 [00:18<00:40,  3.09it/s]\u001b[A\n",
      " 32%|███▏      | 58/181 [00:18<00:39,  3.09it/s]\u001b[A\n",
      " 33%|███▎      | 59/181 [00:19<00:39,  3.09it/s]\u001b[A\n",
      " 33%|███▎      | 60/181 [00:19<00:39,  3.09it/s]\u001b[A\n",
      " 34%|███▎      | 61/181 [00:19<00:38,  3.09it/s]\u001b[A\n",
      " 34%|███▍      | 62/181 [00:19<00:38,  3.09it/s]\u001b[A\n",
      " 35%|███▍      | 63/181 [00:20<00:38,  3.10it/s]\u001b[A\n",
      " 35%|███▌      | 64/181 [00:20<00:37,  3.10it/s]\u001b[A\n",
      " 36%|███▌      | 65/181 [00:20<00:37,  3.10it/s]\u001b[A\n",
      " 36%|███▋      | 66/181 [00:21<00:37,  3.10it/s]\u001b[A\n",
      " 37%|███▋      | 67/181 [00:21<00:36,  3.10it/s]\u001b[A\n",
      " 38%|███▊      | 68/181 [00:21<00:36,  3.10it/s]\u001b[A\n",
      " 38%|███▊      | 69/181 [00:22<00:36,  3.10it/s]\u001b[A\n",
      " 39%|███▊      | 70/181 [00:22<00:35,  3.10it/s]\u001b[A\n",
      " 39%|███▉      | 71/181 [00:22<00:35,  3.10it/s]\u001b[A\n",
      " 40%|███▉      | 72/181 [00:23<00:35,  3.10it/s]\u001b[A\n",
      " 40%|████      | 73/181 [00:23<00:34,  3.10it/s]\u001b[A\n",
      " 41%|████      | 74/181 [00:23<00:34,  3.10it/s]\u001b[A\n",
      " 41%|████▏     | 75/181 [00:24<00:34,  3.10it/s]\u001b[A\n",
      " 42%|████▏     | 76/181 [00:24<00:33,  3.10it/s]\u001b[A\n",
      " 43%|████▎     | 77/181 [00:24<00:33,  3.10it/s]\u001b[A\n",
      " 43%|████▎     | 78/181 [00:25<00:33,  3.10it/s]\u001b[A\n",
      " 44%|████▎     | 79/181 [00:25<00:32,  3.10it/s]\u001b[A\n",
      " 44%|████▍     | 80/181 [00:25<00:32,  3.10it/s]\u001b[A\n",
      " 45%|████▍     | 81/181 [00:26<00:32,  3.10it/s]\u001b[A\n",
      " 45%|████▌     | 82/181 [00:26<00:31,  3.10it/s]\u001b[A\n",
      " 46%|████▌     | 83/181 [00:26<00:31,  3.09it/s]\u001b[A\n",
      " 46%|████▋     | 84/181 [00:27<00:31,  3.10it/s]\u001b[A\n",
      " 47%|████▋     | 85/181 [00:27<00:30,  3.11it/s]\u001b[A\n",
      " 48%|████▊     | 86/181 [00:27<00:30,  3.11it/s]\u001b[A\n",
      " 48%|████▊     | 87/181 [00:28<00:30,  3.10it/s]\u001b[A\n",
      " 49%|████▊     | 88/181 [00:28<00:29,  3.10it/s]\u001b[A\n",
      " 49%|████▉     | 89/181 [00:28<00:29,  3.10it/s]\u001b[A\n",
      " 50%|████▉     | 90/181 [00:29<00:29,  3.10it/s]\u001b[A\n",
      " 50%|█████     | 91/181 [00:29<00:29,  3.10it/s]\u001b[A\n",
      " 51%|█████     | 92/181 [00:29<00:28,  3.10it/s]\u001b[A\n",
      " 51%|█████▏    | 93/181 [00:29<00:28,  3.10it/s]\u001b[A\n",
      " 52%|█████▏    | 94/181 [00:30<00:28,  3.10it/s]\u001b[A\n",
      " 52%|█████▏    | 95/181 [00:30<00:27,  3.10it/s]\u001b[A\n",
      " 53%|█████▎    | 96/181 [00:30<00:27,  3.11it/s]\u001b[A\n",
      " 54%|█████▎    | 97/181 [00:31<00:27,  3.10it/s]\u001b[A\n",
      " 54%|█████▍    | 98/181 [00:31<00:26,  3.10it/s]\u001b[A\n",
      " 55%|█████▍    | 99/181 [00:31<00:26,  3.11it/s]\u001b[A\n",
      " 55%|█████▌    | 100/181 [00:32<00:26,  3.11it/s]\u001b[A\n",
      " 56%|█████▌    | 101/181 [00:32<00:25,  3.10it/s]\u001b[A\n",
      " 56%|█████▋    | 102/181 [00:32<00:25,  3.10it/s]\u001b[A\n",
      " 57%|█████▋    | 103/181 [00:33<00:25,  3.10it/s]\u001b[A\n",
      " 57%|█████▋    | 104/181 [00:33<00:24,  3.09it/s]\u001b[A\n",
      " 58%|█████▊    | 105/181 [00:33<00:24,  3.09it/s]\u001b[A\n",
      " 59%|█████▊    | 106/181 [00:34<00:24,  3.09it/s]\u001b[A\n",
      " 59%|█████▉    | 107/181 [00:34<00:23,  3.10it/s]\u001b[A\n",
      " 60%|█████▉    | 108/181 [00:34<00:23,  3.10it/s]\u001b[A\n",
      " 60%|██████    | 109/181 [00:35<00:23,  3.10it/s]\u001b[A\n",
      " 61%|██████    | 110/181 [00:35<00:22,  3.10it/s]\u001b[A\n",
      " 61%|██████▏   | 111/181 [00:35<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 112/181 [00:36<00:22,  3.10it/s]\u001b[A\n",
      " 62%|██████▏   | 113/181 [00:36<00:21,  3.10it/s]\u001b[A\n",
      " 63%|██████▎   | 114/181 [00:36<00:21,  3.10it/s]\u001b[A\n",
      " 64%|██████▎   | 115/181 [00:37<00:21,  3.10it/s]\u001b[A\n",
      " 64%|██████▍   | 116/181 [00:37<00:20,  3.10it/s]\u001b[A\n",
      " 65%|██████▍   | 117/181 [00:37<00:20,  3.10it/s]\u001b[A\n",
      " 65%|██████▌   | 118/181 [00:38<00:20,  3.10it/s]\u001b[A\n",
      " 66%|██████▌   | 119/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 66%|██████▋   | 120/181 [00:38<00:19,  3.10it/s]\u001b[A\n",
      " 67%|██████▋   | 121/181 [00:39<00:19,  3.11it/s]\u001b[A\n",
      " 67%|██████▋   | 122/181 [00:39<00:18,  3.11it/s]\u001b[A\n",
      " 68%|██████▊   | 123/181 [00:39<00:18,  3.10it/s]\u001b[A\n",
      " 69%|██████▊   | 124/181 [00:39<00:18,  3.10it/s]\u001b[A\n",
      " 69%|██████▉   | 125/181 [00:40<00:18,  3.10it/s]\u001b[A\n",
      " 70%|██████▉   | 126/181 [00:40<00:17,  3.10it/s]\u001b[A\n",
      " 70%|███████   | 127/181 [00:40<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████   | 128/181 [00:41<00:17,  3.10it/s]\u001b[A\n",
      " 71%|███████▏  | 129/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 130/181 [00:41<00:16,  3.10it/s]\u001b[A\n",
      " 72%|███████▏  | 131/181 [00:42<00:16,  3.11it/s]\u001b[A\n",
      " 73%|███████▎  | 132/181 [00:42<00:15,  3.11it/s]\u001b[A\n",
      " 73%|███████▎  | 133/181 [00:42<00:15,  3.10it/s]\u001b[A\n",
      " 74%|███████▍  | 134/181 [00:43<00:15,  3.10it/s]\u001b[A\n",
      " 75%|███████▍  | 135/181 [00:43<00:14,  3.09it/s]\u001b[A\n",
      " 75%|███████▌  | 136/181 [00:43<00:14,  3.09it/s]\u001b[A\n",
      " 76%|███████▌  | 137/181 [00:44<00:14,  3.09it/s]\u001b[A\n",
      " 76%|███████▌  | 138/181 [00:44<00:13,  3.10it/s]\u001b[A\n",
      " 77%|███████▋  | 139/181 [00:44<00:13,  3.10it/s]\u001b[A\n",
      " 77%|███████▋  | 140/181 [00:45<00:13,  3.10it/s]\u001b[A\n",
      " 78%|███████▊  | 141/181 [00:45<00:12,  3.10it/s]\u001b[A\n",
      " 78%|███████▊  | 142/181 [00:45<00:12,  3.11it/s]\u001b[A\n",
      " 79%|███████▉  | 143/181 [00:46<00:12,  3.11it/s]\u001b[A\n",
      " 80%|███████▉  | 144/181 [00:46<00:11,  3.11it/s]\u001b[A\n",
      " 80%|████████  | 145/181 [00:46<00:11,  3.10it/s]\u001b[A\n",
      " 81%|████████  | 146/181 [00:47<00:11,  3.10it/s]\u001b[A\n",
      " 81%|████████  | 147/181 [00:47<00:10,  3.10it/s]\u001b[A\n",
      " 82%|████████▏ | 148/181 [00:47<00:10,  3.11it/s]\u001b[A\n",
      " 82%|████████▏ | 149/181 [00:48<00:10,  3.11it/s]\u001b[A\n",
      " 83%|████████▎ | 150/181 [00:48<00:09,  3.11it/s]\u001b[A\n",
      " 83%|████████▎ | 151/181 [00:48<00:09,  3.10it/s]\u001b[A\n",
      " 84%|████████▍ | 152/181 [00:49<00:09,  3.10it/s]\u001b[A\n",
      " 85%|████████▍ | 153/181 [00:49<00:09,  3.10it/s]\u001b[A\n",
      " 85%|████████▌ | 154/181 [00:49<00:08,  3.10it/s]\u001b[A\n",
      " 86%|████████▌ | 155/181 [00:49<00:08,  3.11it/s]\u001b[A\n",
      " 86%|████████▌ | 156/181 [00:50<00:08,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 157/181 [00:50<00:07,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 158/181 [00:50<00:07,  3.11it/s]\u001b[A\n",
      " 88%|████████▊ | 159/181 [00:51<00:07,  3.11it/s]\u001b[A\n",
      " 88%|████████▊ | 160/181 [00:51<00:06,  3.11it/s]\u001b[A\n",
      " 89%|████████▉ | 161/181 [00:51<00:06,  3.10it/s]\u001b[A\n",
      " 90%|████████▉ | 162/181 [00:52<00:06,  3.10it/s]\u001b[A\n",
      " 90%|█████████ | 163/181 [00:52<00:05,  3.10it/s]\u001b[A\n",
      " 91%|█████████ | 164/181 [00:52<00:05,  3.10it/s]\u001b[A\n",
      " 91%|█████████ | 165/181 [00:53<00:05,  3.11it/s]\u001b[A\n",
      " 92%|█████████▏| 166/181 [00:53<00:04,  3.11it/s]\u001b[A\n",
      " 92%|█████████▏| 167/181 [00:53<00:04,  3.11it/s]\u001b[A\n",
      " 93%|█████████▎| 168/181 [00:54<00:04,  3.11it/s]\u001b[A\n",
      " 93%|█████████▎| 169/181 [00:54<00:03,  3.11it/s]\u001b[A\n",
      " 94%|█████████▍| 170/181 [00:54<00:03,  3.11it/s]\u001b[A\n",
      " 94%|█████████▍| 171/181 [00:55<00:03,  3.11it/s]\u001b[A\n",
      " 95%|█████████▌| 172/181 [00:55<00:02,  3.11it/s]\u001b[A\n",
      " 96%|█████████▌| 173/181 [00:55<00:02,  3.11it/s]\u001b[A\n",
      " 96%|█████████▌| 174/181 [00:56<00:02,  3.11it/s]\u001b[A\n",
      " 97%|█████████▋| 175/181 [00:56<00:01,  3.11it/s]\u001b[A\n",
      " 97%|█████████▋| 176/181 [00:56<00:01,  3.11it/s]\u001b[A\n",
      " 98%|█████████▊| 177/181 [00:57<00:01,  3.11it/s]\u001b[A\n",
      " 98%|█████████▊| 178/181 [00:57<00:00,  3.11it/s]\u001b[A\n",
      " 99%|█████████▉| 179/181 [00:57<00:00,  3.11it/s]\u001b[A\n",
      " 99%|█████████▉| 180/181 [00:58<00:00,  3.11it/s]\u001b[A\n",
      "100%|██████████| 181/181 [00:58<00:00,  3.11it/s]\u001b[A\n",
      "Epoch: 100%|██████████| 4/4 [37:51<00:00, 567.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.54\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:58\n",
      "Training complete!\n",
      "Total training took 0:37:52 (h:mm:ss)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "# for epoch_i in range(0, epochs):\n",
    "for epoch_i in trange(epochs, desc=\"Epoch\"):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "#         print(b_input_ids.dtype)\n",
    "#         print(b_labels.dtype)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "#         loss, logits = model(b_input_ids, \n",
    "#                          token_type_ids=None, \n",
    "#                          attention_mask=b_input_mask, \n",
    "#                          labels=b_labels)\n",
    "        \n",
    "#         print(loss)\n",
    "#         print(logits)\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in tqdm(validation_dataloader):\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "#         print(b_input_ids.dtype)\n",
    "#         print(b_labels.dtype)\n",
    "        \n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "#             loss, logits = model(b_input_ids, \n",
    "#                      token_type_ids=None, \n",
    "#                      attention_mask=b_input_mask, \n",
    "#                      labels=b_labels)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQTvJ1vRP7u4"
   },
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "6O_NbXFGMukX",
    "outputId": "a9e51eda-5eae-4800-87d5-8d016ff25bb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0:08:28</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0:08:30</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0:08:31</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0:08:30</td>\n",
       "      <td>0:00:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.70         0.69           0.54       0:08:28         0:00:58\n",
       "2               0.69         0.69           0.54       0:08:30         0:00:58\n",
       "3               0.69         0.69           0.54       0:08:31         0:00:58\n",
       "4               0.69         0.69           0.54       0:08:30         0:00:58"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "\n",
    "output_dir = './w_freeze_results_updated_clinBERTpretrained_3day_200421/'\n",
    "\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df_stats.to_csv(f'{output_dir}training_stats.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-G03mmwH3aI"
   },
   "source": [
    "Notice that, while the the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data. \n",
    "\n",
    "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
    "\n",
    "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
    "\n",
    "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "68xreA9JAmG5",
    "outputId": "70b8500d-7efc-4c99-de1f-05e8795e6298"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "# plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(f'{output_dir}train_val_loss_figure.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "# 5. Performance On Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DosV94BYIYxg"
   },
   "source": [
    "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_score(df, score, output_dir):\n",
    "    df['pred_score'] = score\n",
    "    df_sort = df.sort_values(by=['ID'])\n",
    "    # score\n",
    "    temp = (df_sort.groupby(['ID'])['pred_score'].agg(max) + df_sort.groupby(['ID'])['pred_score'].agg(sum) / 2) / (\n",
    "                1 + df_sort.groupby(['ID'])['pred_score'].agg(len) / 2)\n",
    "    x = df_sort.groupby(['ID'])['Label'].agg(np.min).values\n",
    "    df_out = pd.DataFrame({'logits': temp.values, 'ID': x})\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(x, temp.values)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='Val (area = {:.3f})'.format(auc_score))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.savefig(f'{output_dir}auroc_BioClinicalbert_3day.png')\n",
    "    plt.show()\n",
    "    \n",
    "#     string = 'auroc_clinicalbert_' + args.readmission_mode + '.png'\n",
    "#     plt.savefig(os.path.join(args.output_dir, string))\n",
    "\n",
    "    return fpr, tpr, df_out\n",
    "\n",
    "\n",
    "def pr_curve_plot(y, y_score, output_dir):\n",
    "    precision, recall, _ = precision_recall_curve(y, y_score)\n",
    "    area = auc(recall, precision)\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve: AUC={0:0.2f}'.format(\n",
    "        area))\n",
    "    \n",
    "    plt.savefig(f'{output_dir}auprc_BioClinicalbert_3day.png')\n",
    "    plt.show()\n",
    "#     string = 'auprc_clinicalbert_' + args.readmission_mode + '.png'\n",
    "\n",
    "#     plt.savefig(os.path.join(args.output_dir, string))\n",
    "\n",
    "\n",
    "def vote_pr_curve(df, score, output_dir):\n",
    "    df['pred_score'] = score\n",
    "    df_sort = df.sort_values(by=['ID'])\n",
    "    # score\n",
    "    temp = (df_sort.groupby(['ID'])['pred_score'].agg(max) + df_sort.groupby(['ID'])['pred_score'].agg(sum) / 2) / (\n",
    "                1 + df_sort.groupby(['ID'])['pred_score'].agg(len) / 2)\n",
    "    y = df_sort.groupby(['ID'])['Label'].agg(np.min).values\n",
    "\n",
    "    precision, recall, thres = precision_recall_curve(y, temp)\n",
    "    pr_thres = pd.DataFrame(data=list(zip(precision, recall, thres)), columns=['prec', 'recall', 'thres'])\n",
    "    vote_df = pd.DataFrame(data=list(zip(temp, y)), columns=['score', 'label'])\n",
    "\n",
    "    pr_curve_plot(y, temp, output_dir)\n",
    "\n",
    "    temp = pr_thres[pr_thres.prec > 0.799999].reset_index()\n",
    "\n",
    "    rp80 = 0\n",
    "    if temp.size == 0:\n",
    "        print('Test Sample too small or RP80=0')\n",
    "    else:\n",
    "        rp80 = temp.iloc[0].recall\n",
    "        print('Recall at Precision of 80 is {}', rp80)\n",
    "\n",
    "    return rp80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg42jJqqM68F"
   },
   "source": [
    "### 5.1. Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWe0_JW21MyV"
   },
   "source": [
    "\n",
    "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAN0LZBOOPVh",
    "outputId": "7385ca3f-72d5-45f0-bbfe-5056c2f62c4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                              | 16/3063 [00:00<00:19, 152.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 3,063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3063/3063 [00:21<00:00, 142.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  date of birth: sex: f service: medicine allergies: haldol attending: chief complaint: delta ms, lethargy, ?sepsis . major surgical or invasive procedure: none history of present illness: hx obtained per ed notes and sister . hpi: 35f with disease who presented today from daycare after her healthcare providers noted that she was lethargic. they were initially unable to obtain a blood pressure. the patient was noted to have a very rapid heart rate. vitals were finally obtained and were as follows: bp 70/50 (baseline sbps 80-90), hr 113, o2 sat 99% on 3l nc. . the patient was transferred to where she was noted to have a temp of 4, hr 200 and sbp 80s. ekg was noteworthy for a wide complex tachycardia. the patient received adenosine 6mg and then 12mg with no improvement. she was cardioverted into sinus rhythm. her d-dimer was elevated at 3590, lactate was 5 and trop t 39 in the setting of renal insufficiency. a ct-a was negative for a pe. the patient was transferred to the micu for further mgmt. . past medical history: disease anemia nonverbal at baseline . social history: meds: tylenol ensure . sochx: patient lives at home with sister and brother. she also goes to daycare. she is non-verbal at baseline. . family history: father who passed away of dz physical exam: t 7, hr 65-68, bp 91-97/61-63, r 14-21, o2 sat 100%2l gen: thin appearing female lying in fetal position in nad heent: mm dry, op clear heart: nl rate, s1s2, no gmr lungs: cta b/l abd: flat, soft, nt, nd, +bs, negative guardin, negative rebound tenderness ext: wwp, +dp b/l neuro: unable to assess . pertinent results: ct-a impression: no evidence of pulmonary embolism. poorly defined opacities within the lungs bilaterally, possibly representing combination of atelectasis and consolidation. air bronchograms in the right middle lobe suggests possible infection. . cxr impression: left lower lobe process suggesting\n",
      "Token IDs: tensor([  101,  2236,  1104,  3485,   131,  2673,   131,   175,  1555,   131,\n",
      "         5182,  1155,  1200, 19310,   131,  5871, 25791,  1233,  6546,   131,\n",
      "         2705, 12522,   131, 20811,   182,  1116,   117,  1519,  7111,  4873,\n",
      "          117,   136, 14516, 17990,   119,  1558, 13467,  1137, 19849,  7791,\n",
      "          131,  3839,  1607,  1104,  1675,  6946,   131,   177,  1775,  3836,\n",
      "         1679,  5048,  3697,  1105,  2104,   119,  6857,  1182,   131,  2588,\n",
      "         2087,  1114,  3653,  1150,  2756,  2052,  1121,  1285, 23340,  1170,\n",
      "         1123, 12520, 12263,  2382,  1115,  1131,  1108,  1519,  7111, 11007,\n",
      "          119,  1152,  1127,  2786,  3372,  1106,  6268,   170,  1892,  2997,\n",
      "          119,  1103,  5351,  1108,  2382,  1106,  1138,   170,  1304,  6099,\n",
      "         1762,  2603,   119,  9301,  1116,  1127,  1921,  3836,  1105,  1127,\n",
      "         1112,  3226,   131,   171,  1643,  3102,   120,  1851,   113,  2259,\n",
      "         2568,   188,  1830,  3491,  2908,   118,  3078,   114,   117,   177,\n",
      "         1197, 12206,   117,   184,  1477,  2068,  4850,   110,  1113,   124,\n",
      "         1233,   183,  1665,   119,   119,  1103,  5351,  1108,  3175,  1106,\n",
      "         1187,  1131,  1108,  2382,  1106,  1138,   170, 21359,  8223,  1104,\n",
      "          125,   117,   177,  1197,  2363,  1105,   188,  1830,  1643, 17008,\n",
      "          119,   174,  1377,  1403,  1108, 22076,  1111,   170,  2043,  2703,\n",
      "        27629,  8992, 10542,  1465,   119,  1103,  5351,  1460,  8050, 26601,\n",
      "        10606,  1162,   127,  1306,  1403,  1105,  1173,  1367,  1306,  1403,\n",
      "         1114,  1185,  8331,   119,  1131,  1108,  3621,  2660, 17534,  1154,\n",
      "        11850,  1361,  6795,   119,  1123,   173,   118, 12563,  1200,  1108,\n",
      "         8208,  1120,  2588, 21500,   117,  2495,  5822,  2193,  1108,   126,\n",
      "         1105,   189, 12736,   189,  3614,  1107,  1103,  3545,  1104,  1231,\n",
      "         7050, 22233,  9435, 23864,   119,   170,   172,  1204,   118,   170,\n",
      "         1108,  4366,  1111,   170,   185,  1162,   119,  1103,  5351,  1108,\n",
      "         3175,  1106,  1103,  1940, 10182,  1111,  1748, 17713,  1306,  1204,\n",
      "          119,   119,  1763,  2657,  1607,   131,  3653,  1126, 20504,  1664,\n",
      "         4121,  7767,  1120,  2259,  2568,   119,  1934,  1607,   131,  1143,\n",
      "         3680,   131,   189, 12415,  2728,  1233,  4989,   119,  1177,  1732,\n",
      "         1775,   131,  5351,  2491,  1120,  1313,  1114,  2104,  1105,  1711,\n",
      "          119,  1131,  1145,  2947,  1106,  1285, 23340,   119,  1131,  1110,\n",
      "         1664,   118, 14093,  1120,  2259,  2568,   119,   119,  1266,  1607,\n",
      "          131,  1401,  1150,  2085,  1283,  1104,   173,  1584,  2952, 12211,\n",
      "          131,   189,   128,   117,   177,  1197,  2625,   118,  5599,   117,\n",
      "          171,  1643,  5539,   118,  5311,   120,  5391,   118,  5519,   117,\n",
      "          187,  1489,   118,  1626,   117,   184,  1477,  2068,  1620,   110,\n",
      "          123,  1233,   176,  1424,   131,  4240,  5452,  2130,  4009,  1107,\n",
      "          175, 21470,  1700,  1107,  9468,  1181,  1119,  3452,   131,  2608,\n",
      "         3712,   117, 11769,  2330,  1762,   131,   183,  1233,  2603,   117,\n",
      "          188,  1475,  1116,  1477,   117,  1185,   176,  1306,  1197,  8682,\n",
      "          131,   172,  1777,   171,   120,   181,   170,  1830,  1181,   131,\n",
      "         3596,   117,  2991,   117,   183,  1204,   117,   183,  1181,   117,\n",
      "          116,   171,  1116,   117,  4366,  3542,  1394,   117,  4366,  1231,\n",
      "         8346,  8886,  1757,  4252,  1204,   131,   192,  2246,  1643,   117,\n",
      "          116,   173,  1643,   171,   120,   181, 24928, 11955,   131,  3372,\n",
      "         1106, 15187,   119,  1679, 24123,  2686,   131,   172,  1204,   118,\n",
      "          170,  8351,   131,  1185,  2554,  1104, 26600,  9712, 15792,  1863,\n",
      "          119,  9874,  3393, 11769,  7409,  4233,  1439,  1103,  8682, 20557,\n",
      "         1193,   117,  3566,  4311,  4612,  1104,  8756, 18465, 14229,  1105,\n",
      "        20994,   119,  1586,  9304,  1320,  8401, 12139,  1116,  1107,  1103,\n",
      "         1268,   102])\n",
      "returning TensorDataset! \n",
      "3063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = preprocess_tokenize_embed_data(\"./data/discharge/test.csv\")\n",
    "\n",
    "print(len(test_dataset))\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16lctEOyNFik"
   },
   "source": [
    "## 5.2. Evaluate on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cells below are for 2 label classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhR99IISNMg9"
   },
   "source": [
    "\n",
    "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     './model/updated_BioClinicalBERT_3day_190421/', # Use the 12-layer BERT model, with an uncased vocab.\n",
    "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "#                     # You can increase this for multi-class tasks.   \n",
    "#     output_attentions = False, # Whether the model returns attentions weights.\n",
    "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "# )\n",
    "# model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hba10sXR7Xi6",
    "outputId": "e35f0a6e-72c5-4bd0-9c4b-dcec9ef5059d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 96/96 [03:50<00:00,  2.40s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at Precision of 80 is {} 0.12413793103448276\n",
      "  Accuracy: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58      1366\n",
      "           1       0.66      0.66      0.66      1697\n",
      "\n",
      "    accuracy                           0.62      3063\n",
      "   macro avg       0.62      0.62      0.62      3063\n",
      "weighted avg       0.62      0.62      0.62      3063\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-4577f78d1aab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Readmitted vs not readmitted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_cf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Blues'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;31m# plt.savefig(f\"{output_dir}Confusion_Matrix.png\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from funcsigs import signature\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, auc, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook\n",
    "# Prediction on test set\n",
    "output_dir = \"./results/results_updated_BioClinicalBERTpretrained_discharge_220421/\"\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "load_pretrained = True\n",
    "if load_pretrained:\n",
    "    #reload other model perhaps: \n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        './model/results_updated_BioClinicalBERTpretrained_discharge_220421/', # Use the 12-layer BERT model, with an uncased vocab.\n",
    "        num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                        # You can increase this for multi-class tasks.   \n",
    "        output_attentions = False, # Whether the model returns attentions weights.\n",
    "        output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "    )\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "else:\n",
    "    print(\"hopefully you ran another model earlier and are using that!\")\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "logits_history, pred_labels , true_labels = [], [], []\n",
    "\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in tqdm(test_dataloader):\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "\n",
    "\n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask,\n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "#             loss, logits = model(b_input_ids, \n",
    "#                      token_type_ids=None, \n",
    "#                      attention_mask=b_input_mask, \n",
    "#                      labels=b_labels)\n",
    "\n",
    "    # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "    # output values prior to applying an activation function like the \n",
    "    # softmax.\n",
    "    loss = result.loss\n",
    "    logits = result.logits\n",
    "    \n",
    "\n",
    "    # Accumulate the evaluation loss.\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "\n",
    "    \n",
    "      # Store predictions and true labels\n",
    "        \n",
    "\n",
    "    logits_history.append(logits)\n",
    "\n",
    "    pred_labels.append(np.argmax(logits, axis=1).flatten())\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    \n",
    "#     def flat_accuracy(preds, labels):\n",
    "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#     labels_flat = labels.flatten()\n",
    "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "\n",
    "# concatenate a bunch of these     \n",
    "logits_history = np.concatenate(logits_history, axis=0)\n",
    "pred_labels = np.concatenate(pred_labels, axis = 0 )\n",
    "true_labels = np.concatenate(true_labels, axis = 0)\n",
    "\n",
    "\n",
    "# put logits, predicted labels and true labels in a dataframe to use the vote_score and vote_pr_curve\n",
    "df = pd.DataFrame({'logits': logits_history[:,1], 'pred_label': pred_labels, 'label': true_labels})\n",
    "#         string = 'logits_clinicalbert_' + readmission_mode + '_chunks.csv'\n",
    "#         df.to_csv(os.path.join(output_dir, string))\n",
    "# df.to_csv(f'{output_dir}logits_preds_truths.csv')\n",
    "\n",
    "df_test = pd.read_csv(\"./data/discharge/test.csv\")\n",
    "fpr, tpr, df_out = vote_score(df_test, logits_history[:,1], output_dir = output_dir)\n",
    "\n",
    "# string = 'logits_clinicalbert_' + readmission_mode + '_readmissions.csv'\n",
    "# df_out.to_csv(f'{output_dir}logits_BioClinicalBert_discharge.csv')\n",
    "\n",
    "rp80 = vote_pr_curve(df_test, logits_history[:,1], output_dir=output_dir)\n",
    "\n",
    "# Report the final accuracy for this test run.\n",
    "avg_test_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "print(\"  Accuracy: {0:.2f}\".format(avg_test_accuracy))\n",
    "\n",
    "# Calculate the average loss over all of the batches.\n",
    "avg_test_loss = total_eval_loss / len(test_dataloader)\n",
    "\n",
    "# print(\"  Evaluation on test Loss: {0:.2f}\".format(avg_test_loss))\n",
    "\n",
    "# preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "#save classification report as a dataframe to csv\n",
    "pd.DataFrame(classification_report(true_labels,pred_labels, output_dict=True)).to_csv(f\"{output_dir}_classification_report.csv\")\n",
    "\n",
    "\n",
    "cf = confusion_matrix(true_labels, pred_labels, normalize = 'true')\n",
    "df_cf = pd.DataFrame(cf, ['not r/a', 'readmitted'], ['not r/a', 'readmitted'])\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.suptitle(\"Readmitted vs not readmitted\")\n",
    "sns.heatmap(df_cf, annot = True, cmap = 'Blues')\n",
    "# plt.savefig(f\"{output_dir}Confusion_Matrix.png\")\n",
    "\n",
    "# Record all statistics from this test\n",
    "\n",
    "test_result = {'eval_loss': avg_test_loss,\n",
    "          'eval_accuracy': avg_test_accuracy,          \n",
    "          'RP80': rp80}\n",
    "pd.DataFrame(test_result).to_csv(f\"{output_dir}_test_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(2.0266e-06, device='cuda:0'), logits=tensor([[ 6.2789, -6.8144]], device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.5607940446650124,\n",
       "  'recall': 0.6235711470240441,\n",
       "  'f1-score': 0.5905188503172826,\n",
       "  'support': 2537},\n",
       " '1': {'precision': 0.6354961832061069,\n",
       "  'recall': 0.5733471074380165,\n",
       "  'f1-score': 0.6028240405503259,\n",
       "  'support': 2904},\n",
       " 'accuracy': 0.5967653004962323,\n",
       " 'macro avg': {'precision': 0.5981451139355596,\n",
       "  'recall': 0.5984591272310303,\n",
       "  'f1-score': 0.5966714454338042,\n",
       "  'support': 5441},\n",
       " 'weighted avg': {'precision': 0.6006644747924409,\n",
       "  'recall': 0.5967653004962323,\n",
       "  'f1-score': 0.5970864431194802,\n",
       "  'support': 5441}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(true_labels,pred_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "108\n",
      "108\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 0, 1]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 1, 1]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0]),\n",
       " array([0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 0, 0, 1, 0]),\n",
       " array([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 1]),\n",
       " array([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 1, 1]),\n",
       " array([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0]),\n",
       " array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 1, 1, 1, 1]),\n",
       " array([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 0, 0]),\n",
       " array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 1]),\n",
       " array([0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 0, 0]),\n",
       " array([1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 0, 1]),\n",
       " array([1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0]),\n",
       " array([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1]),\n",
       " array([0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 1, 0]),\n",
       " array([1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0]),\n",
       " array([0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 0, 0, 0, 1, 1]),\n",
       " array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1]),\n",
       " array([1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1]),\n",
       " array([0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 1, 0, 1, 1]),\n",
       " array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1]),\n",
       " array([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1]),\n",
       " array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1]),\n",
       " array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 1, 1]),\n",
       " array([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 1, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0]),\n",
       " array([0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1]),\n",
       " array([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1]),\n",
       " array([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 1]),\n",
       " array([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 1, 1, 1, 0]),\n",
       " array([1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 0]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 0, 1, 0]),\n",
       " array([0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1]),\n",
       " array([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0]),\n",
       " array([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 0, 1]),\n",
       " array([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 0, 0, 0]),\n",
       " array([1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 1, 1]),\n",
       " array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 0, 1, 1, 0, 0, 1, 1]),\n",
       " array([0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1]),\n",
       " array([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 1, 1, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0]),\n",
       " array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 1, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 1, 0])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-d7cd83dd2e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59      1595\n",
      "           1       0.65      0.60      0.62      1861\n",
      "\n",
      "    accuracy                           0.61      3456\n",
      "   macro avg       0.61      0.61      0.61      3456\n",
      "weighted avg       0.61      0.61      0.61      3456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(np.concatenate(true_labels,axis=0), np.concatenate(pred_labels, axis=0)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5472"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5441, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5jscIM8R4Gv"
   },
   "source": [
    "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
    "\n",
    "We use MCC here because the classes are imbalanced:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWcy0X1hirdx",
    "outputId": "ef5e6753-c244-406a-8141-5078d71b04ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 354 of 516 (68.60%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRaZQ4XC7kLs",
    "outputId": "d922af70-1216-4cfb-ac37-1dde75744fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/cdthome/xiz325/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(logits_history[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculate and store the coef for this batch.  \n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUM0UA1qJaVB"
   },
   "source": [
    "The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches. \n",
    "\n",
    "Each batch has 32 sentences in it, except the last batch which has only (516 % 32) = 4 test sentences in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "pyfY1tqxU0t9",
    "outputId": "5e477de2-e6a9-466a-9b36-f3651f2996df"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a barplot showing the MCC score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(logits_history, axis=0)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      7.57\n",
       "1      4.13\n",
       "2      6.93\n",
       "3      6.51\n",
       "4      5.52\n",
       "       ... \n",
       "379   -6.82\n",
       "380   -7.46\n",
       "381   -6.78\n",
       "382   -3.13\n",
       "383   -7.75\n",
       "Name: 1, Length: 384, dtype: float32"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.concatenate(logits_history, axis=0))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(pred_labels, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3456,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(true_labels, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YrjAPX2V-l4"
   },
   "source": [
    "Now we'll combine the results for all of the batches and calculate our final MCC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCYZa1lQ8Jn8",
    "outputId": "b4650298-0e35-4ed8-be13-83f074a617ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.218\n"
     ]
    }
   ],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(logits_history, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3456,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(flat_predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXx0jPc4HUfZ"
   },
   "source": [
    "Cool! In about half an hour and without doing any hyperparameter tuning (adjusting the learning rate, epochs, batch size, ADAM properties, etc.) we are able to get a good score. \n",
    "\n",
    "> *Note: To maximize the score, we should remove the \"validation set\" (which we used to help determine how many epochs to train for) and train on the entire training set.*\n",
    "\n",
    "The library documents the expected accuracy for this benchmark [here](https://huggingface.co/transformers/examples.html#glue) as `49.23`.\n",
    "\n",
    "You can also look at the official leaderboard [here](https://gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy). \n",
    "\n",
    "Note that (due to the small dataset size?) the accuracy can vary significantly between runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfjYoa6WmkN6"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlQG7qgkmf4n"
   },
   "source": [
    "This post demonstrates that with a pre-trained BERT model you can quickly and effectively create a high quality model with minimal effort and training time using the pytorch interface, regardless of the specific NLP task you are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUmsUOIv8EUO"
   },
   "source": [
    "# Appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2079Qyn8Mt8"
   },
   "source": [
    "## A1. Saving & Loading Fine-Tuned Model\n",
    "\n",
    "This first cell (taken from `run_glue.py` [here](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) writes the model and tokenizer out to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ulTWaOr8QNY",
    "outputId": "1b73b37b-2598-4992-d6d7-0649f410b5c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./results_updated_BioClinicalBERT_3day_190421/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./results_updated_BioClinicalBERT_3day_190421/tokenizer_config.json',\n",
       " './results_updated_BioClinicalBERT_3day_190421/special_tokens_map.json',\n",
       " './results_updated_BioClinicalBERT_3day_190421/vocab.txt',\n",
       " './results_updated_BioClinicalBERT_3day_190421/added_tokens.json')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "\n",
    "# torch.save(model.state_dict(), output_dir + \"pytorch_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-tjHkR7lc1I"
   },
   "source": [
    "Let's check out the file sizes, out of curiosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqMzI3VTCZo5",
    "outputId": "96104fe5-67d0-4310-d778-58da5194c2e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 428000K\n",
      "-rw-r--r-- 1 root root      1K Feb  2 17:10 config.json\n",
      "-rw-r--r-- 1 root root 427757K Feb  2 17:10 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root      1K Feb  2 17:10 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root      1K Feb  2 17:10 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root    227K Feb  2 17:10 vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l --block-size=K ./model_save/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr_bt2rFlgDn"
   },
   "source": [
    "The largest file is the model weights, at around 418 megabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WUFUIQ8Cu8D",
    "outputId": "b0c9b6c6-5fb8-4d61-d28a-be4324be5a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 418M Feb  2 17:10 ./model_save/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -l --block-size=M ./model_save/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzGKvOFAll_e"
   },
   "source": [
    "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Trr-A-POC18_"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to this Notebook instance.\n",
    "from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxlZsafTC-V5"
   },
   "outputs": [],
   "source": [
    "# Copy the model files to a directory in your Google Drive.\n",
    "!cp -r ./model_save/ \"./drive/Shared drives/ChrisMcCormick.AI/Blog Posts/BERT Fine-Tuning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0vstijw85SZ"
   },
   "source": [
    "The following functions will load the model back from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nskPzUM084zL"
   },
   "outputs": [],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIWouvDrGVAi"
   },
   "source": [
    "## A.2. Weight Decay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f123ZAlF1OyW"
   },
   "source": [
    "The huggingface example includes the following code block for enabling weight decay, but the default decay rate is \"0.0\", so I moved this to the appendix.\n",
    "\n",
    "This block essentially tells the optimizer to not apply weight decay to the bias terms (e.g., $ b $ in the equation $ y = Wx + b $ ). Weight decay is a form of regularization--after calculating the gradients, we multiply them by, e.g., 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxSMw0FrptiL"
   },
   "outputs": [],
   "source": [
    "# This code is taken from:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
    "\n",
    "# Don't apply weight decay to any parameters whose names include these tokens.\n",
    "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "# Separate the `weight` parameters from the `bias` parameters. \n",
    "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n",
    "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n",
    "optimizer_grouped_parameters = [\n",
    "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.1},\n",
    "    \n",
    "    # Filter for parameters which *do* include those.\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n",
    "# the names."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Fine-Tuning Sentence Classification v4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fe5b1d0540240a8a8426352c24b2887": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1058e0b5baa248faa60c1ad146d10bf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1296a3d754b344a482a03e5af84e805e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8874fec8a404ae89a38fd2ecbb357cf",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2755b9838bae408ca8cf667ad9d501fc",
      "value": 433
     }
    },
    "1c2b0ede959142fc89bf07a9c88df638": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ca9359e6c44232a1346e6f2ab7e48c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe5b1d0540240a8a8426352c24b2887",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c7dec7b1e804c2195f6e60fb3c1d18e",
      "value": 440473133
     }
    },
    "2755b9838bae408ca8cf667ad9d501fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "375cc635389c4ddb9bf2aa443df58bae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "440da34c72344cb08e4a1ee5de7049ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "472198d5b6a748b3a81f9364fd1fa711": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b1e27aff6f04fec8268d951e46b1e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c7dec7b1e804c2195f6e60fb3c1d18e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6f132d7bb83d41b6847df0d0ec0a1b92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_978c24b18b594eaf8ca47730a88eefb9",
      "placeholder": "​",
      "style": "IPY_MODEL_a7bdbedc75de4f77b45f1389c2ea0abc",
      "value": " 433/433 [00:00&lt;00:00, 2.02kB/s]"
     }
    },
    "82ddfcea0e4c4e5a86cf6eca8585be8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c76faadf2f4415393c6f0a805f0d72b",
       "IPY_MODEL_e0bb735fda99434a90380e7fc664212d"
      ],
      "layout": "IPY_MODEL_8a256ba4a19e4ec98fe3c3c99fba4daa"
     }
    },
    "8a256ba4a19e4ec98fe3c3c99fba4daa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c76faadf2f4415393c6f0a805f0d72b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1058e0b5baa248faa60c1ad146d10bf7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdb78e75309f4bc09366533331e72431",
      "value": 231508
     }
    },
    "978c24b18b594eaf8ca47730a88eefb9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7bdbedc75de4f77b45f1389c2ea0abc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf9dfa1ff3e642fbb74c5146d21044c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1296a3d754b344a482a03e5af84e805e",
       "IPY_MODEL_6f132d7bb83d41b6847df0d0ec0a1b92"
      ],
      "layout": "IPY_MODEL_1c2b0ede959142fc89bf07a9c88df638"
     }
    },
    "cdb78e75309f4bc09366533331e72431": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cea84f9c3db641acb98314028b305514": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d689bc8d488a4dc09c393b4fc9747bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_440da34c72344cb08e4a1ee5de7049ee",
      "placeholder": "​",
      "style": "IPY_MODEL_4b1e27aff6f04fec8268d951e46b1e63",
      "value": " 440M/440M [00:07&lt;00:00, 55.5MB/s]"
     }
    },
    "e0bb735fda99434a90380e7fc664212d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_472198d5b6a748b3a81f9364fd1fa711",
      "placeholder": "​",
      "style": "IPY_MODEL_375cc635389c4ddb9bf2aa443df58bae",
      "value": " 232k/232k [00:00&lt;00:00, 616kB/s]"
     }
    },
    "f8874fec8a404ae89a38fd2ecbb357cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe254c3bcc08402eb506f0e98f5673a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23ca9359e6c44232a1346e6f2ab7e48c",
       "IPY_MODEL_d689bc8d488a4dc09c393b4fc9747bcb"
      ],
      "layout": "IPY_MODEL_cea84f9c3db641acb98314028b305514"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
