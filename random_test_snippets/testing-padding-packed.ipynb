{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2c6326",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The above answers addressed the question why very well. I just want to add an example for better understanding the use of pack_padded_sequence.\n",
    "Let's take an example\n",
    "\n",
    "    Note: pack_padded_sequence requires sorted sequences in the batch (in the descending order of sequence lengths). In the below example, the sequence batch were already sorted for less cluttering. Visit this gist link for the full implementation.\n",
    "\n",
    "First, we create a batch of 2 sequences of different sequence lengths as below. We have 7 elements in the batch totally.\n",
    "\n",
    "    Each sequence has embedding size of 2.\n",
    "    The first sequence has the length: 5\n",
    "    The second sequence has the length: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40773843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn\n",
    "seq_batch = [torch.tensor([[1, 1],\n",
    "                           [2, 2],\n",
    "                           [3, 3],\n",
    "                           [4, 4],\n",
    "                           [5, 5]]),\n",
    "             torch.tensor([[10, 10],\n",
    "                           [20, 20]])]\n",
    "\n",
    "seq_lens = [5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15394da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_batch[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a5c9a",
   "metadata": {},
   "source": [
    "We pad seq_batch to get the batch of sequences with equal length of 5 (The max length in the batch). Now, the new batch has 10 elements totally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f767e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5]],\n",
      "\n",
      "        [[10, 10],\n",
      "         [20, 20],\n",
      "         [ 0,  0],\n",
      "         [ 0,  0],\n",
      "         [ 0,  0]]])\n",
      "torch.Size([2, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# pad the seq_batch\n",
    "\n",
    "padded_seq_batch = torch.nn.utils.rnn.pad_sequence(seq_batch, batch_first=True)\n",
    "\n",
    "print(padded_seq_batch)\n",
    "print(padded_seq_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbedbf6",
   "metadata": {},
   "source": [
    "Then, we pack the padded_seq_batch. It returns a tuple of two tensors:\n",
    "\n",
    "    The first is the data including all the elements in the sequence batch.\n",
    "    The second is the batch_sizes which will tell how the elements related to each other by the steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4968897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 1,  1],\n",
       "        [10, 10],\n",
       "        [ 2,  2],\n",
       "        [20, 20],\n",
       "        [ 3,  3],\n",
       "        [ 4,  4],\n",
       "        [ 5,  5]]), batch_sizes=tensor([2, 2, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pack the padded_seq_batch\n",
    "packed_seq_batch = torch.nn.utils.rnn.pack_padded_sequence(padded_seq_batch, lengths=seq_lens, batch_first=True)\n",
    "packed_seq_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa83f4",
   "metadata": {},
   "source": [
    "Now, we pass the tuple packed_seq_batch to the recurrent modules in Pytorch, such as RNN, LSTM. This only requires 5 + 2=7 computations in the recurrrent module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "341e7922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-7.0842e-02,  8.0181e-02, -2.9316e-02],\n",
       "        [-5.8671e-01,  2.2299e-03, -1.4920e-04],\n",
       "        [-2.6730e-01,  8.7460e-02, -3.7573e-02],\n",
       "        [-9.1874e-01,  1.2688e-05, -6.9973e-05],\n",
       "        [-5.0493e-01,  6.0212e-02, -3.5421e-02],\n",
       "        [-6.8296e-01,  3.7609e-02, -2.8522e-02],\n",
       "        [-7.8116e-01,  2.3925e-02, -2.0730e-02]], grad_fn=<CatBackward>), batch_sizes=tensor([2, 2, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=2, hidden_size=3, batch_first=True)\n",
    "output, (hn, cn) = lstm(packed_seq_batch.float()) # pass float tensor instead long tensor.\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0df0b9",
   "metadata": {},
   "source": [
    "We need to convert output back to the padded batch of output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ddb786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.0842e-02,  8.0181e-02, -2.9316e-02],\n",
       "         [-2.6730e-01,  8.7460e-02, -3.7573e-02],\n",
       "         [-5.0493e-01,  6.0212e-02, -3.5421e-02],\n",
       "         [-6.8296e-01,  3.7609e-02, -2.8522e-02],\n",
       "         [-7.8116e-01,  2.3925e-02, -2.0730e-02]],\n",
       "\n",
       "        [[-5.8671e-01,  2.2299e-03, -1.4920e-04],\n",
       "         [-9.1874e-01,  1.2688e-05, -6.9973e-05],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_output, output_lens = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True, total_length=5)\n",
    "padded_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27690ce",
   "metadata": {},
   "source": [
    "as you can see the model did not computer any gradients or weights for the pad elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1db845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
